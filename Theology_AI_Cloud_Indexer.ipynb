{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ­ Theology AI Lab - Cloud Indexer\n",
    "\n",
    "ì´ ë…¸íŠ¸ë¶ì€ **Google Drive**ì— ì €ì¥ëœ ì‹ í•™ ë¬¸ì„œ(PDF/EPUB)ë¥¼ **T4 GPU**ë¥¼ ì‚¬ìš©í•˜ì—¬ ê³ ì†ìœ¼ë¡œ ì¸ë±ì‹±í•©ë‹ˆë‹¤.\n",
    "\n",
    "### ğŸš€ ì‚¬ìš©ë²•\n",
    "1. **`01_Library/inbox`** í´ë”ì— PDF íŒŒì¼ì„ ë„£ìœ¼ì„¸ìš”.\n",
    "2. ìƒë‹¨ ë©”ë‰´ì˜ **`ëŸ°íƒ€ì„ > ëª¨ë‘ ì‹¤í–‰`**ì„ í´ë¦­í•˜ì„¸ìš”.\n",
    "3. ì™„ë£Œë˜ë©´ ë¡œì»¬ Streamlit ì•±ì—ì„œ ê²€ìƒ‰í•˜ì„¸ìš”.\n",
    "\n",
    "### ğŸ“‚ í•„ìš”í•œ í´ë” êµ¬ì¡° (êµ¬ê¸€ ë“œë¼ì´ë¸Œ)\n",
    "```\n",
    "ë‚´ ë“œë¼ì´ë¸Œ/Theology_AI_LAB/\n",
    "â”œâ”€â”€ 01_Library/inbox/     â† PDF íŒŒì¼ì„ ì—¬ê¸°ì— ë„£ìœ¼ì„¸ìš” (í•˜ìœ„ í´ë” ì§€ì›)\n",
    "â”œâ”€â”€ 01_Library/archive/   â† ì²˜ë¦¬ ì™„ë£Œëœ íŒŒì¼\n",
    "â””â”€â”€ 02_Brain/vector_db/   â† ìë™ ìƒì„±ë¨\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1ï¸âƒ£ êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "print('âœ… ë“œë¼ì´ë¸Œ ì—°ê²° ì™„ë£Œ!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2ï¸âƒ£ í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ (ì•½ 1ë¶„ ì†Œìš”)\n",
    "print('ğŸ“¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ì¤‘...')\n",
    "!pip install -q langchain langchain-community langchain-chroma chromadb sentence-transformers pymupdf pytesseract rank_bm25 ebooklib beautifulsoup4\n",
    "!apt-get install -y tesseract-ocr > /dev/null 2>&1\n",
    "print('âœ… ì„¤ì¹˜ ì™„ë£Œ!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3ï¸âƒ£ GitHubì—ì„œ ìµœì‹  ì¸ë±ì„œ ì½”ë“œ ë‹¤ìš´ë¡œë“œ\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "GITHUB_RAW_BASE = 'https://raw.githubusercontent.com/mitmirsein/Theology_Ai_Lab/main/03_System'\n",
    "WORK_DIR = Path('/content/theology_indexer')\n",
    "WORK_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "# í•„ìš”í•œ íŒŒì¼ë“¤ ë‹¤ìš´ë¡œë“œ\n",
    "files_to_download = [\n",
    "    'processor_v4.py',\n",
    "    'pipeline/__init__.py',\n",
    "    'pipeline/embedder.py',\n",
    "    'pipeline/metadata_parser.py',\n",
    "    'pipeline/semantic_chunker.py',\n",
    "    'pipeline/router.py',\n",
    "    'pipeline/chunker.py',\n",
    "    'pipeline/searcher.py',\n",
    "    'utils/__init__.py',\n",
    "    'utils/ocr_pdf_processor.py',\n",
    "    'utils/page_number_detector.py',\n",
    "]\n",
    "\n",
    "print('ğŸ“¥ GitHubì—ì„œ ìµœì‹  ì½”ë“œ ë‹¤ìš´ë¡œë“œ ì¤‘...')\n",
    "for f in files_to_download:\n",
    "    url = f'{GITHUB_RAW_BASE}/{f}'\n",
    "    local_path = WORK_DIR / f\n",
    "    # ë¶€ëª¨ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±\n",
    "    local_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    !wget -q -O \"{local_path}\" \"{url}\" 2>/dev/null || echo \"âš ï¸ {f} ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨\"\n",
    "\n",
    "# Python ê²½ë¡œì— ì¶”ê°€\n",
    "import sys\n",
    "if str(WORK_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(WORK_DIR))\n",
    "\n",
    "print('âœ… ì½”ë“œ ì¤€ë¹„ ì™„ë£Œ!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4ï¸âƒ£ ê²½ë¡œ ì„¤ì •\n",
    "PROJECT_ROOT = Path('/content/drive/MyDrive/Theology_AI_LAB')\n",
    "\n",
    "inbox_dir = PROJECT_ROOT / '01_Library/inbox'\n",
    "archive_dir = PROJECT_ROOT / '01_Library/archive'\n",
    "db_dir = PROJECT_ROOT / '02_Brain/vector_db'\n",
    "\n",
    "# í´ë” ìƒì„± (ì—†ìœ¼ë©´)\n",
    "inbox_dir.mkdir(parents=True, exist_ok=True)\n",
    "archive_dir.mkdir(parents=True, exist_ok=True)\n",
    "db_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f'ğŸ“‚ Inbox: {inbox_dir}')\n",
    "print(f'ğŸ“¦ Archive: {archive_dir}')\n",
    "print(f'ğŸ§  Vector DB: {db_dir}')\n",
    "\n",
    "# Inbox íŒŒì¼ í™•ì¸ (í•˜ìœ„ í´ë” í¬í•¨ ì¬ê·€ ê²€ìƒ‰ rglob ì‚¬ìš©)\n",
    "inbox_files = list(inbox_dir.rglob('*.pdf')) + list(inbox_dir.rglob('*.epub')) + list(inbox_dir.rglob('*.txt'))\n",
    "print(f'\\nğŸ“„ ì²˜ë¦¬ ëŒ€ê¸° íŒŒì¼: {len(inbox_files)}ê°œ')\n",
    "for f in inbox_files[:5]:\n",
    "    print(f'   - {f.name}')\n",
    "if len(inbox_files) > 5:\n",
    "    print(f'   ... ì™¸ {len(inbox_files)-5}ê°œ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5ï¸âƒ£ ì¸ë±ì‹± ì‹¤í–‰\n",
    "if len(inbox_files) == 0:\n",
    "    print('âš ï¸ Inboxì— íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤!')\n",
    "    print('ğŸ’¡ êµ¬ê¸€ ë“œë¼ì´ë¸Œì˜ Theology_AI_LAB/01_Library/inbox/ í´ë”(ë˜ëŠ” í•˜ìœ„ í´ë”)ì— PDF íŒŒì¼ì„ ë„£ì–´ì£¼ì„¸ìš”.')\n",
    "else:\n",
    "    print('ğŸš€ ì¸ë±ì‹±ì„ ì‹œì‘í•©ë‹ˆë‹¤...\\n')\n",
    "    \n",
    "    from processor_v4 import ProjectV4Processor\n",
    "    \n",
    "    processor = ProjectV4Processor(db_dir=str(db_dir))\n",
    "    \n",
    "    # processor ë‚´ë¶€ì—ì„œë„ rglobì„ ì‚¬ìš©í•˜ë¯€ë¡œ í•˜ìœ„ í´ë” íŒŒì¼ë„ ì˜ ì²˜ë¦¬ë©ë‹ˆë‹¤.\n",
    "    for update in processor.index_files_with_progress(inbox_dir, archive_dir):\n",
    "        status = update.get('status')\n",
    "        msg = update.get('message')\n",
    "        \n",
    "        if status == 'indexing':\n",
    "            print(f'ğŸ“– {msg}')\n",
    "        elif status == 'done':\n",
    "            print(f'\\nğŸ‰ {msg}')\n",
    "            stats = update.get('session_stats', {})\n",
    "            print(f'   - ì²˜ë¦¬ëœ íŒŒì¼: {stats.get(\"processed_files\", 0)}')\n",
    "            print(f'   - ì´ ì²­í¬: {stats.get(\"total_chunks\", 0)}')\n",
    "        elif status == 'error':\n",
    "            print(f'âŒ ì˜¤ë¥˜: {msg}')\n",
    "    \n",
    "    print('\\n' + '='*50)\n",
    "    print('âœ… ì™„ë£Œ! ë¡œì»¬ ì•±ì—ì„œ ê²€ìƒ‰í•´ë³´ì„¸ìš”.')\n",
    "    print('='*50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.12"
  },
  "accelerator": "GPU"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
