#!/usr/bin/env python3
"""
Theology AI Lab - Streamlit GUI
================================
ë¡œì»¬ ì‹ í•™ ì—°êµ¬ ë°ì´í„°ë² ì´ìŠ¤ ì¸í„°í˜ì´ìŠ¤

ì‹¤í–‰: streamlit run app.py
"""

import os

# tokenizers fork í¬ë˜ì‹œ ë°©ì§€ (ë©€í‹°ìŠ¤ë ˆë“œ í™˜ê²½ì—ì„œ subprocess í˜¸ì¶œ ì‹œ ì¶©ëŒ ë°©ì§€)
os.environ["TOKENIZERS_PARALLELISM"] = "false"
import sys
import json
import shutil
from pathlib import Path
from datetime import datetime

import streamlit as st

# ê²½ë¡œ ì„¤ì •
SCRIPT_DIR = Path(__file__).parent.absolute()
KIT_ROOT = SCRIPT_DIR.parent

sys.path.insert(0, str(SCRIPT_DIR))
sys.path.insert(0, str(SCRIPT_DIR / "utils"))

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
from dotenv import load_dotenv
ENV_FILE = KIT_ROOT / ".env"
load_dotenv(ENV_FILE)

# ì „ì—­ ì„¤ì • ë¡œë“œ
def load_global_settings():
    settings = {
        "ANTHROPIC_API_KEY": os.getenv("ANTHROPIC_API_KEY", ""),
        "OPENAI_API_KEY": os.getenv("OPENAI_API_KEY", ""),
        "GOOGLE_API_KEY": os.getenv("GOOGLE_API_KEY", ""),
        "RAG_MODEL": os.getenv("RAG_MODEL", "gemini-2.5-flash"),
        "RAG_MAX_TOKENS": os.getenv("RAG_MAX_TOKENS", "4096"),
        "APP_TITLE": os.getenv("APP_TITLE", "Kerygma Th Library"),
        "OBSIDIAN_VAULT": os.getenv("OBSIDIAN_VAULT", ""),
    }
    # .env íŒŒì¼ì´ ìˆìœ¼ë©´ ìš°ì„ ì ìœ¼ë¡œ ë®ì–´ì“°ê¸° (ì‹¤ì‹œê°„ ë°˜ì˜ìš©)
    if ENV_FILE.exists():
        with open(ENV_FILE, "r", encoding="utf-8") as f:
            for line in f:
                line = line.strip()
                if line and not line.startswith("#") and "=" in line:
                    key, value = line.split("=", 1)
                    key = key.strip()
                    value = value.strip().strip('"').strip("'")
                    if key in settings:
                        settings[key] = value
    return settings

GLOBAL_SETTINGS = load_global_settings()
APP_TITLE = GLOBAL_SETTINGS["APP_TITLE"]

# ê²½ë¡œ ì„¤ì • (ìƒëŒ€ ê²½ë¡œëŠ” KIT_ROOT ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜)
def resolve_path(env_var: str, default: str) -> Path:
    """í™˜ê²½ ë³€ìˆ˜ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜"""
    val = os.getenv(env_var, default)
    if val is None:
        val = default
    if val.startswith("."):
        return (KIT_ROOT / val).resolve()
    return Path(val)

INBOX_DIR = resolve_path("INBOX_DIR", "./01_Library/inbox")
ARCHIVE_DIR = resolve_path("ARCHIVE_DIR", "./01_Library/archive")
DB_PATH = resolve_path("CHROMA_DB_DIR", "./02_Brain/vector_db")
LEMMA_INDEX_PATH = ARCHIVE_DIR / "lemma_index.json"

# ============================================================
# í˜ì´ì§€ ì„¤ì •
# ============================================================
st.set_page_config(
    page_title=APP_TITLE,
    page_icon="ğŸ“œ",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ============================================================
# ìºì‹œëœ ë¦¬ì†ŒìŠ¤ ë¡œë“œ
# ============================================================
@st.cache_resource
def load_model():
    """ì„ë² ë”© ëª¨ë¸ ë¡œë“œ"""
    from sentence_transformers import SentenceTransformer
    return SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

@st.cache_resource
def load_db(_db_path: str):
    """ChromaDB ì—°ê²°"""
    import chromadb
    db_path = Path(_db_path)
    if not db_path.exists():
        return None, None
    client = chromadb.PersistentClient(path=_db_path)
    try:
        collection = client.get_collection(name="theology_library")
        return client, collection
    except:
        return client, None

@st.cache_data(ttl=60)
def load_lemma_index(_index_path: str):
    """Lemma ì¸ë±ìŠ¤ ë¡œë“œ (v1.0 ë° v2.0 í˜•ì‹ ëª¨ë‘ ì§€ì›)"""
    index_path = Path(_index_path)
    if not index_path.exists():
        return None
    with open(index_path, "r", encoding="utf-8") as f:
        data = json.load(f)

    # v2.0 í˜•ì‹ì¸ì§€ í™•ì¸ (entries í‚¤ê°€ ìˆëŠ”ì§€)
    if "entries" in data:
        return data

    # v1.0 í˜•ì‹ â†’ v2.0 í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    # v1.0: {"lemma": [{file, page}, ...], ...}
    # v2.0: {"entries": {...}, "by_category": {}, "by_source": {...}, "updated_at": ...}
    entries = {}
    by_source = {}

    for lemma, occurrences in data.items():
        entries[lemma] = []
        for occ in occurrences:
            source_file = occ.get("file", "")
            source_name = source_file.replace(".json", "") if source_file else "Unknown"
            page = occ.get("page", 0)

            entries[lemma].append({
                "file": source_file,
                "page": page,
                "source": source_name
            })

            # by_source ì§‘ê³„
            if source_name not in by_source:
                by_source[source_name] = {"count": 0, "volumes": []}
            by_source[source_name]["count"] += 1

    return {
        "version": "1.0 (converted)",
        "updated_at": datetime.now().isoformat(),
        "entries": entries,
        "by_category": {},  # v1.0ì—ëŠ” ì¹´í…Œê³ ë¦¬ ì •ë³´ ì—†ìŒ
        "by_source": by_source
    }


def get_sources_from_db() -> dict:
    """
    ChromaDBì—ì„œ ì§ì ‘ ì†ŒìŠ¤ ëª©ë¡ê³¼ ì²­í¬ ìˆ˜ ì¡°íšŒ

    Returns:
        {"source_name": {"count": int}, ...}
    """
    import chromadb
    from collections import defaultdict

    try:
        client = chromadb.PersistentClient(path=str(DB_PATH))
        collection = client.get_collection(name="theology_library")
    except Exception:
        return {}

    # ëª¨ë“  ë¬¸ì„œì˜ ë©”íƒ€ë°ì´í„° ì¡°íšŒ
    results = collection.get(include=["metadatas"])

    if not results.get("metadatas"):
        return {}

    # ì†ŒìŠ¤ë³„ ì§‘ê³„
    source_counts = defaultdict(int)
    for meta in results["metadatas"]:
        source = meta.get("source", "Unknown")
        source_counts[source] += 1

    return {source: {"count": count} for source, count in source_counts.items()}


def delete_source_from_db(source_name: str) -> int:
    """
    ChromaDBì—ì„œ íŠ¹ì • ì†ŒìŠ¤ì˜ ëª¨ë“  ì²­í¬ ì‚­ì œ

    Args:
        source_name: ì‚­ì œí•  ì†ŒìŠ¤ ì´ë¦„ (ì˜ˆ: "TRE_Bd04")

    Returns:
        ì‚­ì œëœ ì²­í¬ ìˆ˜
    """
    import chromadb

    client = chromadb.PersistentClient(path=str(DB_PATH))
    try:
        collection = client.get_collection(name="theology_library")
    except Exception:
        return 0

    # í•´ë‹¹ ì†ŒìŠ¤ì˜ ëª¨ë“  ë¬¸ì„œ ID ì¡°íšŒ
    results = collection.get(
        where={"source": source_name},
        include=[]
    )

    ids_to_delete = results.get("ids", [])
    if not ids_to_delete:
        return 0

    # ì‚­ì œ ì‹¤í–‰
    collection.delete(ids=ids_to_delete)

    # ìºì‹œ ë¬´íš¨í™”
    load_db.clear()
    load_lemma_index.clear()

    return len(ids_to_delete)


def reindex_source(source_name: str) -> str:
    """
    ì†ŒìŠ¤ ì¬ì¸ë±ì‹±: DBì—ì„œ ì‚­ì œ í›„ ì•„ì¹´ì´ë¸Œì—ì„œ ë‹¤ì‹œ ì¸ë±ì‹±

    Args:
        source_name: ì¬ì¸ë±ì‹±í•  ì†ŒìŠ¤ ì´ë¦„

    Returns:
        ê²°ê³¼ ë©”ì‹œì§€
    """
    import chromadb
    from sentence_transformers import SentenceTransformer

    # 1. ì•„ì¹´ì´ë¸Œ íŒŒì¼ í™•ì¸
    archive_file = ARCHIVE_DIR / f"{source_name}.json"
    if not archive_file.exists():
        raise FileNotFoundError(f"ì•„ì¹´ì´ë¸Œ íŒŒì¼ ì—†ìŒ: {archive_file}")

    # 2. ê¸°ì¡´ ë°ì´í„° ì‚­ì œ
    deleted_count = delete_source_from_db(source_name)

    # 3. ì•„ì¹´ì´ë¸Œì—ì„œ ë°ì´í„° ë¡œë“œ
    with open(archive_file, "r", encoding="utf-8") as f:
        first_char = f.read(1)
        f.seek(0)

        if first_char == "[":
            data = json.load(f)
        else:
            raw_data = json.load(f)
            if isinstance(raw_data, dict) and "chunks" in raw_data:
                data = raw_data["chunks"]
            elif isinstance(raw_data, dict):
                data = [raw_data]
            else:
                data = [raw_data]

    if not data:
        return f"ì‚­ì œ {deleted_count}ê°œ, ë°ì´í„° ì—†ìŒ"

    # 4. ëª¨ë¸ ë° DB ì—°ê²°
    model = SentenceTransformer("paraphrase-multilingual-MiniLM-L12-v2")
    client = chromadb.PersistentClient(path=str(DB_PATH))
    collection = client.get_or_create_collection(name="theology_library")

    # 5. ì¬ì¸ë±ì‹±
    documents = []
    ids = []
    metadatas = []

    for item in data:
        unique_id = f"{source_name}_{item.get('id', hash(item.get('text', '')))}"
        meta = item.get("metadata", {})
        meta["source"] = source_name
        meta["indexed_at"] = datetime.now().isoformat()
        meta["reindexed"] = True  # ì¬ì¸ë±ì‹± í‘œì‹œ

        # None ë° ë¦¬ìŠ¤íŠ¸ ì²˜ë¦¬
        for k, v in list(meta.items()):
            if v is None:
                meta[k] = ""
            elif isinstance(v, list):
                meta[k] = ", ".join(str(x) for x in v)

        documents.append(item["text"])
        ids.append(unique_id)
        metadatas.append(meta)

    # ë°°ì¹˜ ì²˜ë¦¬
    batch_size = 10
    for i in range(0, len(documents), batch_size):
        batch_docs = documents[i:i + batch_size]
        batch_ids = ids[i:i + batch_size]
        batch_meta = metadatas[i:i + batch_size]

        embeddings = model.encode(batch_docs).tolist()
        collection.upsert(
            ids=batch_ids,
            documents=batch_docs,
            embeddings=embeddings,
            metadatas=batch_meta
        )

    # ìºì‹œ ë¬´íš¨í™”
    load_db.clear()
    load_lemma_index.clear()

    return f"ì‚­ì œ {deleted_count}ê°œ â†’ ìƒˆë¡œ ì¸ë±ì‹± {len(documents)}ê°œ"


def check_duplicate_source(source_name: str) -> dict:
    """
    ì¤‘ë³µ ì¸ë±ì‹± ì—¬ë¶€ í™•ì¸

    Returns:
        {"exists": bool, "count": int, "indexed_at": str}
    """
    import chromadb

    client = chromadb.PersistentClient(path=str(DB_PATH))
    try:
        collection = client.get_collection(name="theology_library")
    except Exception:
        return {"exists": False, "count": 0, "indexed_at": None}

    results = collection.get(
        where={"source": source_name},
        include=["metadatas"],
        limit=1
    )

    if not results.get("ids"):
        return {"exists": False, "count": 0, "indexed_at": None}

    # ì „ì²´ ê°œìˆ˜ ì¡°íšŒ
    all_results = collection.get(
        where={"source": source_name},
        include=[]
    )

    indexed_at = None
    if results.get("metadatas"):
        indexed_at = results["metadatas"][0].get("indexed_at", "")

    return {
        "exists": True,
        "count": len(all_results.get("ids", [])),
        "indexed_at": indexed_at
    }


# ============================================================
# ì‚¬ì´ë“œë°”
# ============================================================
# íƒ€ì´í‹€ ì²˜ë¦¬ (Theology AI Labì¸ ê²½ìš° ë¶„í•  í‘œì‹œ)
title_main = APP_TITLE
title_sub = ""
if "Theology" in APP_TITLE and "AI Lab" in APP_TITLE:
    title_sub = "Theology"
    title_main = "AI Lab"

# ì„œë¸Œ íƒ€ì´í‹€ HTML ìƒì„±
if title_sub:
    sub_title_html = f'<div style="font-size: 0.8em; font-weight: 700; color: #FFFFFF; text-transform: uppercase; letter-spacing: 2px; text-shadow: 0 2px 4px rgba(0,0,0,0.3);">{title_sub}</div>'
else:
    sub_title_html = ""

# HTML ìƒì„± (ì™„ì „ ì¸ë¼ì¸ ë¬¸ìì—´ ê²°í•© ë°©ì‹)
sidebar_html = (
    '<div style="text-align: center; padding: 15px 0 25px 0;">'
    '<div style="margin-bottom: 10px;">'
    + sub_title_html +
    f'<div style="font-size: 1.5em; font-weight: 900; color: #FFFFFF; letter-spacing: 0.5px; text-shadow: 0 2px 4px rgba(0,0,0,0.3);">{title_main}</div>'
    '</div>'
    '<div style="display: inline-block; background: linear-gradient(135deg, #7C3AED 0%, #6B21A8 100%); color: white; padding: 4px 16px; border-radius: 20px; font-size: 0.7em; font-weight: 700; letter-spacing: 0.5px; box-shadow: 0 2px 8px rgba(124, 58, 237, 0.4);">'
    'v2.7 Premium'
    '</div>'
    '</div>'
)

st.sidebar.markdown(sidebar_html, unsafe_allow_html=True)
st.sidebar.markdown("---")

page = st.sidebar.radio(
    "ë©”ë‰´",
    ["ğŸ” ê²€ìƒ‰", "ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ“Š í†µê³„", "âš™ï¸ ì„¤ì •"],
    label_visibility="collapsed"
)

st.sidebar.markdown("---")

# ì˜µì‹œë””ì–¸ ì—´ê¸° ë²„íŠ¼
if st.sidebar.button("ğŸŸ£ ì˜µì‹œë””ì–¸ ì—´ê¸°", use_container_width=True):
    # ìµœì‹  ê²½ë¡œë¥¼ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ ì—¬ëŸ¬ ì†ŒìŠ¤ í™•ì¸
    vault_path_final = ""
    
    # 1. ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ (ì„¤ì • í˜ì´ì§€ì—ì„œ ì…ë ¥ ì¤‘ì¸ ê°’)
    if st.session_state.get("obsidian_vault_input"):
        vault_path_final = st.session_state.get("obsidian_vault_input", "").strip()
    
    # 2. ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì˜ ì €ì¥ëœ ì„¤ì •
    if not vault_path_final and st.session_state.get("current_settings"):
        vault_path_final = st.session_state.current_settings.get("OBSIDIAN_VAULT", "").strip()
    
    # 3. .env íŒŒì¼ ì§ì ‘ ì½ê¸° (ìµœí›„ ìˆ˜ë‹¨)
    if not vault_path_final and ENV_FILE.exists():
        with open(ENV_FILE, "r", encoding="utf-8") as f:
            for line in f:
                if line.strip().startswith("OBSIDIAN_VAULT="):
                    vault_path_final = line.strip().split("=", 1)[1].strip().strip('"').strip("'")
                    break
    
    if vault_path_final:
        import subprocess
        import platform
        from urllib.parse import quote
        
        # ì „ì²´ ê²½ë¡œë¥¼ URL ì¸ì½”ë”©í•˜ì—¬ ì‚¬ìš© (path= ë°©ì‹)
        path_encoded = quote(vault_path_final)
        obsidian_uri = f"obsidian://open?path={path_encoded}"
        
        vault_name = Path(vault_path_final).name
        st.sidebar.caption(f"ğŸš€ ì‹¤í–‰: {vault_name}")
        
        try:
            if platform.system() == "Darwin":
                subprocess.run(["open", obsidian_uri])
            elif platform.system() == "Windows":
                os.startfile(obsidian_uri)
            else:
                subprocess.run(["xdg-open", obsidian_uri])
        except Exception as e:
            st.sidebar.error(f"ì‹¤í–‰ ì‹¤íŒ¨: {e}")
    else:
        st.sidebar.warning("âš ï¸ ì„¤ì • > Obsidian ê²½ë¡œë¥¼ ë¨¼ì € ì…ë ¥í•˜ì„¸ìš”")

st.sidebar.markdown("---")
st.sidebar.markdown(
    """
    <div style="text-align: center; font-size: 0.85em; padding-top: 10px;">
        <a href="https://www.kerygma.co.kr" target="_blank" style="color: #6B46C1; text-decoration: none; font-weight: 600; display: inline-flex; align-items: center; gap: 5px;">
            <span>â˜•</span> ì±… í•œ ê¶Œ ì‚¬ì£¼ì…”ì„œ ì‘ì›í•´ì£¼ì„¸ìš”
        </a>
        <br><br>
        <div style="color: #A0AEC0; font-size: 0.8em; line-height: 1.4;">
            Â© 2025 Kerygma Press<br>
            <span style="letter-spacing: 1px; font-weight: 500;">INTELLIGENT SCRIBE</span>
        </div>
    </div>
    """,
    unsafe_allow_html=True
)

# ============================================================
# AI ë¦¬í¬íŠ¸ ìƒì„± í•¨ìˆ˜
# ============================================================
def generate_ai_report(query: str, context: str, provider: str, model_name: str, api_key: str) -> str:
    """
    ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ AIê°€ ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±

    Args:
        query: ê²€ìƒ‰ ì§ˆë¬¸
        context: ê²€ìƒ‰ ê²°ê³¼ í…ìŠ¤íŠ¸
        provider: API í”„ë¡œë°”ì´ë” (anthropic, openai, google)
        model_name: ëª¨ë¸ ì´ë¦„
        api_key: API í‚¤

    Returns:
        AI ìƒì„± ë¦¬í¬íŠ¸
    """
    system_prompt = """ë‹¹ì‹ ì€ ì‹ í•™ ì—°êµ¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œê³µëœ ì‹ í•™ ë¬¸í—Œ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ í•™ìˆ ì ìœ¼ë¡œ ì •í™•í•˜ê³  ê¹Šì´ ìˆëŠ” ë¶„ì„ì„ ì œê³µí•˜ì„¸ìš”.

ê·œì¹™:
1. ì œê³µëœ ìë£Œì— ê·¼ê±°í•˜ì—¬ ë‹µë³€í•˜ì„¸ìš”
2. ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš” (ì˜ˆ: "TREì— ë”°ë¥´ë©´...")
3. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”
4. í•™ìˆ ì  í†¤ì„ ìœ ì§€í•˜ì„¸ìš”
5. ìë£Œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ˆì„¸ìš”"""

    user_prompt = f"""ì§ˆë¬¸: {query}

ì°¸ê³  ìë£Œ:
{context}

ìœ„ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§ˆë¬¸ì— ëŒ€í•œ ë¶„ì„ ë¦¬í¬íŠ¸ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”."""

    try:
        if provider == "anthropic":
            import anthropic
            client = anthropic.Anthropic(api_key=api_key)
            response = client.messages.create(
                model=model_name,
                max_tokens=4096,
                system=system_prompt,
                messages=[{"role": "user", "content": user_prompt}]
            )
            return response.content[0].text

        elif provider == "openai":
            import openai
            client = openai.OpenAI(api_key=api_key)
            response = client.chat.completions.create(
                model=model_name,
                max_tokens=4096,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ]
            )
            return response.choices[0].message.content

        elif provider == "google":
            from google import genai
            from google.genai import types
            
            client = genai.Client(api_key=api_key)
            response = client.models.generate_content(
                model=model_name,
                contents=f"{system_prompt}\n\n{user_prompt}",
                config=types.GenerateContentConfig(max_output_tokens=4096)
            )
            return response.text

        else:
            return f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” í”„ë¡œë°”ì´ë”: {provider}"

    except Exception as e:
        return f"âŒ AI ë¦¬í¬íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}"


def get_active_api_config() -> tuple:
    """í˜„ì¬ ì„¤ì •ëœ API ì •ë³´ ë°˜í™˜ (provider, model, api_key)"""
    if not ENV_FILE.exists():
        return None, None, None

    settings = {}
    with open(ENV_FILE, "r") as f:
        for line in f:
            line = line.strip()
            if line and not line.startswith("#") and "=" in line:
                key, value = line.split("=", 1)
                settings[key.strip()] = value.strip().strip('"').strip("'")

    model_name = settings.get("RAG_MODEL", "")

    # ëª¨ë¸ëª…ìœ¼ë¡œ í”„ë¡œë°”ì´ë” ì¶”ë¡ 
    if model_name.startswith("claude"):
        provider = "anthropic"
        api_key = settings.get("ANTHROPIC_API_KEY", "")
    elif model_name.startswith("gpt"):
        provider = "openai"
        api_key = settings.get("OPENAI_API_KEY", "")
    elif model_name.startswith("gemini"):
        provider = "google"
        api_key = settings.get("GOOGLE_API_KEY", "")
    else:
        return None, None, None

    if not api_key:
        return None, None, None

    return provider, model_name, api_key


def run_pipeline(chunk_size: int, overlap: int, target_file: str = None):
    """ì¸ë±ì‹± íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ë° ì‹¤ì‹œê°„ ë¡œê·¸ í‘œì‹œ"""
    try:
        import subprocess
        
        cmd = [
            sys.executable, 
            str(SCRIPT_DIR / "utils" / "pipeline.py"),
            "--chunk-size", str(chunk_size),
            "--overlap", str(overlap)
        ]
        
        # v2.6: íŠ¹ì • íŒŒì¼ì´ ì§€ì •ëœ ê²½ìš° ì¸ìë¡œ ì¶”ê°€
        if target_file:
            cmd.append(target_file)
        
        with st.status(f"ğŸ—ï¸ ì¸ë±ì‹± íŒŒì´í”„ë¼ì¸ ê°€ë™ ì¤‘{' (ê°œë³„ íŒŒì¼)' if target_file else ''}...", expanded=True) as log_status:
            log_output = st.empty()
            prog_container = st.empty()
            current_log = []
            
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
                universal_newlines=True
            )
            
            for line in process.stdout:
                line = line.strip()
                if not line: continue
                
                if "[PROGRESS]" in line:
                    try:
                        # [v2.7.23] ê°œì„ ëœ ì§„í–‰ë¥  íŒŒì‹± (í¼ì„¼íŠ¸ + ìƒíƒœ ë©”ì‹œì§€)
                        parts = line.split("[PROGRESS]")[1].strip()
                        pct_str = parts.split("%")[0].strip()
                        prog_val = int(pct_str)
                        # ê´„í˜¸ ì´í›„ ë˜ëŠ” % ì´í›„ì˜ ë©”ì‹œì§€ ì¶”ì¶œ
                        if "%" in parts:
                            status_msg = parts.split("%", 1)[1].strip()
                        else:
                            status_msg = ""
                        prog_container.progress(prog_val / 100, f"ì§„í–‰ë¥ : {prog_val}% {status_msg}")
                    except:
                        pass
                else:
                    current_log.append(line)
                    log_output.code("\n".join(current_log[-15:]))
                    
            process.wait()
            
            if process.returncode == 0:
                log_status.update(label="âœ… ëª¨ë“  íŒŒì¼ ì²˜ë¦¬ ì™„ë£Œ!", state="complete", expanded=False)
                st.success("ğŸ‰ ì„œì¬ ì—…ë°ì´íŠ¸ê°€ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤.")
                load_db.clear()
                load_lemma_index.clear()
                st.session_state.page_mappings = {}
                
                # [v2.7.23] ì™„ë£Œ í›„ ì•ˆë‚´ë¥¼ ìœ„í•œ ì„¸ì…˜ ìƒíƒœ ì„¤ì • ë° í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨
                st.session_state["pipeline_completed"] = True
                st.rerun()  # í˜ì´ì§€ ìƒˆë¡œê³ ì¹¨ìœ¼ë¡œ ìƒë‹¨ ì•ˆë‚´ íŒ¨ë„ í‘œì‹œ
            else:
                log_status.update(label="âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ", state="error")
                st.error(f"íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹¤íŒ¨ (Exit Code: {process.returncode})")
                
    except Exception as e:
        st.error(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")

# ============================================================
# ê²€ìƒ‰ í˜ì´ì§€
# ============================================================
if page == "ğŸ” ê²€ìƒ‰":
    st.markdown(f"""
        <div style="padding-bottom: 25px;">
            <h1 style="color: #2D3748; font-weight: 800; letter-spacing: -0.5px; margin-bottom: 0;">ğŸ” {APP_TITLE} ê²€ìƒ‰</h1>
            <p style="color: #718096; font-size: 1.1em; font-weight: 400;">ê¸°ë¡ëœ ì§€í˜œì˜ ë°”ë‹¤ì—ì„œ í•„ìš”í•œ ë¬¸ì¥ì„ ê±´ì ¸ì˜¬ë¦¬ì„¸ìš”.</p>
        </div>
    """, unsafe_allow_html=True)

    model = load_model()
    client, collection = load_db(str(DB_PATH))

    if collection is None:
        st.warning("âš ï¸ ë°ì´í„°ë² ì´ìŠ¤ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. ë¨¼ì € íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    else:
        st.caption(f"ğŸ“š ì¸ë±ì‹±ëœ ì²­í¬: {collection.count()}ê°œ")

        # ê²€ìƒ‰ ì…ë ¥
        query = st.text_input(
            "ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”",
            placeholder="ì˜ˆ: ì¹­ì˜, Gnade, Rechtfertigung..."
        )

        col1, col2 = st.columns([3, 1])
        with col2:
            n_results = st.selectbox("ê²°ê³¼ ìˆ˜", [5, 10, 20], index=0)

        if query:
            with st.spinner("ê²€ìƒ‰ ì¤‘..."):
                # ë²¡í„° ê²€ìƒ‰
                query_vec = model.encode([query]).tolist()
                results = collection.query(
                    query_embeddings=query_vec,
                    n_results=n_results
                )

            if results['documents'] and results['documents'][0]:
                st.markdown(f"### ê²€ìƒ‰ ê²°ê³¼ ({len(results['documents'][0])}ê±´)")

                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„± í•¨ìˆ˜
                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                def generate_search_report(query: str, results: dict) -> str:
                    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ë¡œ ë³€í™˜"""
                    report_lines = [
                        f"# ê²€ìƒ‰ ë¦¬í¬íŠ¸: {query}",
                        f"",
                        f"**ê²€ìƒ‰ì¼**: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
                        f"**ê²°ê³¼ ìˆ˜**: {len(results['documents'][0])}ê±´",
                        f"",
                        "---",
                        "",
                    ]

                    for i, doc in enumerate(results['documents'][0]):
                        meta = results['metadatas'][0][i]
                        source = meta.get('source', 'Unknown')
                        page_num = meta.get('page_number', '?')
                        lemma = meta.get('lemma', '')
                        category = meta.get('category', '')

                        report_lines.append(f"## [{i+1}] {source} - p.{page_num}")
                        if lemma:
                            report_lines.append(f"**í‘œì œì–´**: {lemma}")
                        if category:
                            report_lines.append(f"**ë¶„ë¥˜**: {category}")
                        report_lines.append("")
                        report_lines.append(doc)
                        report_lines.append("")
                        report_lines.append("---")
                        report_lines.append("")

                    report_lines.append(f"*Generated by {APP_TITLE}*")
                    return "\n".join(report_lines)

                # ë¦¬í¬íŠ¸ ìƒì„±
                markdown_report = generate_search_report(query, results)

                # ì˜µì‹œë””ì–¸ìœ¼ë¡œ ë‚´ë³´ë‚´ê¸° í•¨ìˆ˜
                def save_to_obsidian(content: str, filename: str) -> tuple:
                    """ì˜µì‹œë””ì–¸ Vaultì— ë§ˆí¬ë‹¤ìš´ íŒŒì¼ ì €ì¥"""
                    # ê²½ë¡œ í™•ì¸ (ì‚¬ì´ë“œë°” ë²„íŠ¼ê³¼ ë™ì¼í•œ ë°©ì‹)
                    vault_path_str = ""
                    
                    # 1. ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ (ì„¤ì • í˜ì´ì§€ì—ì„œ ì…ë ¥ ì¤‘ì¸ ê°’)
                    if st.session_state.get("obsidian_vault_input"):
                        vault_path_str = st.session_state.get("obsidian_vault_input", "").strip()
                    
                    # 2. ì„¸ì…˜ ìŠ¤í…Œì´íŠ¸ì˜ ì €ì¥ëœ ì„¤ì •
                    if not vault_path_str and st.session_state.get("current_settings"):
                        vault_path_str = st.session_state.current_settings.get("OBSIDIAN_VAULT", "").strip()
                    
                    # 3. .env íŒŒì¼ ì§ì ‘ ì½ê¸°
                    if not vault_path_str and ENV_FILE.exists():
                        with open(ENV_FILE, "r", encoding="utf-8") as f:
                            for line in f:
                                if line.strip().startswith("OBSIDIAN_VAULT="):
                                    vault_path_str = line.strip().split("=", 1)[1].strip().strip('"').strip("'")
                                    break
                    
                    if not vault_path_str:
                        return False, "Obsidian Vault ê²½ë¡œê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."

                    vault_path = Path(vault_path_str)
                    if not vault_path.exists():
                        return False, f"Vault ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {vault_path}"

                    # íŒŒì¼ëª… ì •ë¦¬ (íŠ¹ìˆ˜ë¬¸ì ì œê±°)
                    safe_filename = "".join(c if c.isalnum() or c in "._- " else "_" for c in filename)
                    file_path = vault_path / f"{safe_filename}.md"

                    try:
                        with open(file_path, "w", encoding="utf-8") as f:
                            f.write(content)
                        return True, str(file_path)
                    except Exception as e:
                        return False, str(e)

                # ë³µì‚¬/ë‹¤ìš´ë¡œë“œ/ì˜µì‹œë””ì–¸/AI ë¦¬í¬íŠ¸ ë²„íŠ¼
                export_col1, export_col2, export_col3, export_col4 = st.columns([1, 1, 1, 1])
                with export_col1:
                    st.download_button(
                        label="ğŸ“¥ ë‹¤ìš´ë¡œë“œ",
                        data=markdown_report,
                        file_name=f"search_{query.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d')}.md",
                        mime="text/markdown",
                        key="download_report"
                    )
                with export_col2:
                    if st.button("ğŸ“‹ ë³µì‚¬", key="copy_report"):
                        st.session_state["report_to_copy"] = markdown_report
                        st.success("âœ… ì•„ë˜ì—ì„œ ë³µì‚¬í•˜ì„¸ìš”")
                with export_col3:
                    if st.button("ğŸŸ£ ì˜µì‹œë””ì–¸", key="obsidian_report"):
                        filename = f"ê²€ìƒ‰_{query}_{datetime.now().strftime('%Y%m%d_%H%M')}"
                        success, result = save_to_obsidian(markdown_report, filename)
                        if success:
                            st.success(f"âœ… ì €ì¥ë¨: {Path(result).name}")
                        else:
                            st.error(f"âŒ {result}")
                with export_col4:
                    # API ì„¤ì • í™•ì¸
                    provider, model_name, api_key = get_active_api_config()
                    if provider and api_key:
                        if st.button("ğŸ¤– AI ë¶„ì„", key="ai_report"):
                            st.session_state["generate_ai_report"] = True
                    else:
                        if st.button("ğŸ¤– AI ë¶„ì„", key="ai_report_disabled", disabled=True):
                            pass
                        st.caption("âš ï¸ ì„¤ì •ì—ì„œ API í‚¤ ë“±ë¡ í•„ìš”")

                # AI ë¦¬í¬íŠ¸ ìƒì„±
                if st.session_state.get("generate_ai_report"):
                    provider, model_name, api_key = get_active_api_config()
                    if provider and api_key:
                        with st.spinner(f"ğŸ¤– AI ë¶„ì„ ì¤‘... ({model_name})"):
                            # ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
                            context_parts = []
                            for i, doc in enumerate(results['documents'][0]):
                                meta = results['metadatas'][0][i]
                                source = meta.get('source', 'Unknown')
                                page_num = meta.get('page_number', '?')
                                context_parts.append(f"[ì¶œì²˜: {source}, p.{page_num}]\n{doc}")

                            context = "\n\n---\n\n".join(context_parts)

                            # AI ë¦¬í¬íŠ¸ ìƒì„±
                            ai_report = generate_ai_report(query, context, provider, model_name, api_key)

                        st.session_state["ai_report_content"] = ai_report
                        st.session_state["generate_ai_report"] = False
                        st.rerun()

                # AI ë¦¬í¬íŠ¸ í‘œì‹œ
                if st.session_state.get("ai_report_content"):
                    st.markdown("---")
                    st.markdown("### ğŸ¤– AI ë¶„ì„ ë¦¬í¬íŠ¸")
                    st.markdown(st.session_state["ai_report_content"])

                    # AI ë¦¬í¬íŠ¸ ë‚´ë³´ë‚´ê¸° ë²„íŠ¼
                    ai_col1, ai_col2, ai_col3 = st.columns([1, 1, 1])
                    with ai_col1:
                        st.download_button(
                            label="ğŸ“¥ AI ë¦¬í¬íŠ¸ ë‹¤ìš´ë¡œë“œ",
                            data=st.session_state["ai_report_content"],
                            file_name=f"ai_report_{query.replace(' ', '_')}_{datetime.now().strftime('%Y%m%d')}.md",
                            mime="text/markdown",
                            key="download_ai_report"
                        )
                    with ai_col2:
                        if st.button("ğŸŸ£ ì˜µì‹œë””ì–¸ ì €ì¥", key="obsidian_ai_report"):
                            filename = f"AIë¶„ì„_{query}_{datetime.now().strftime('%Y%m%d_%H%M')}"
                            # í•¨ìˆ˜ ë‚´ë¶€ì—ì„œ ìë™ìœ¼ë¡œ ê²½ë¡œë¥¼ ê°€ì ¸ì˜´
                            success, result = save_to_obsidian(st.session_state["ai_report_content"], filename)
                            if success:
                                st.success(f"âœ… ì €ì¥ë¨: {Path(result).name}")
                            else:
                                st.error(f"âŒ {result}")
                    with ai_col3:
                        if st.button("ğŸ—‘ï¸ ë‹«ê¸°", key="close_ai_report"):
                            st.session_state["ai_report_content"] = None
                            st.rerun()

                    st.markdown("---")

                # ë³µì‚¬ìš© í…ìŠ¤íŠ¸ ì˜ì—­ (ë²„íŠ¼ í´ë¦­ ì‹œ í‘œì‹œ)
                if st.session_state.get("report_to_copy"):
                    with st.expander("ğŸ“‹ ë³µì‚¬í•  ë‚´ìš© (Ctrl+A, Ctrl+C)", expanded=True):
                        st.code(st.session_state["report_to_copy"], language="markdown")
                        if st.button("ë‹«ê¸°", key="close_copy"):
                            st.session_state["report_to_copy"] = None
                            st.rerun()

                st.markdown("---")

                # ê°œë³„ ê²°ê³¼ í‘œì‹œ
                for i, doc in enumerate(results['documents'][0]):
                    meta = results['metadatas'][0][i]

                    # ì¶œì²˜ ì •ë³´
                    source = meta.get('source', 'Unknown')
                    page_num = meta.get('page_number', '?')
                    lemma = meta.get('lemma', '')
                    category = meta.get('category', '')

                    # ì¹´ë“œ í˜•ì‹ìœ¼ë¡œ í‘œì‹œ
                    with st.expander(f"**[{i+1}] {source}** - p.{page_num} {f'| {lemma}' if lemma else ''}", expanded=(i==0)):
                        if category:
                            st.caption(f"ğŸ“‚ {category}")
                        st.markdown(doc)
            else:
                st.info("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")

# ============================================================
# íŒŒì¼ ì—…ë¡œë“œ í˜ì´ì§€
# ============================================================
elif page == "ğŸ“¤ íŒŒì¼ ì—…ë¡œë“œ":
    st.markdown("""
        <div style="padding-bottom: 25px;">
            <h1 style="color: #2D3748; font-weight: 800; letter-spacing: -0.5px; margin-bottom: 0;">ğŸ“¤ ì‹ ê·œ ìë£Œ ë“±ë¡</h1>
            <p style="color: #718096; font-size: 1.1em; font-weight: 400;">ìƒˆë¡œìš´ ì—°êµ¬ ìë£Œë¥¼ ì„œì¬ì— ë“±ë¡í•˜ê³  AIì˜ ì§€ì„±ì„ ë”í•˜ì„¸ìš”.</p>
        </div>
    """, unsafe_allow_html=True)

    # [v2.7.23] íŒŒì´í”„ë¼ì¸ ì™„ë£Œ í›„ ì•ˆë‚´ (ì„¸ì…˜ ìƒíƒœ ì§€ì†)
    if st.session_state.get("pipeline_completed", False):
        st.markdown("---")
        st.markdown("### ğŸ‰ ì¸ë±ì‹± ì™„ë£Œ!")
        col_result1, col_result2 = st.columns(2)
        with col_result1:
            st.info("""
            **âœ… ì™„ë£Œëœ ì‘ì—…:**
            - ğŸ“„ PDF â†’ í…ìŠ¤íŠ¸ ì¶”ì¶œ
            - âœ‚ï¸ ì²­í‚¹ (ì˜ë¯¸ ë‹¨ìœ„ ë¶„í• )
            - ğŸ§  ë²¡í„° ì„ë² ë”© ìƒì„±
            - ğŸ—„ï¸ ChromaDB ì¸ë±ì‹±
            - ğŸ“¦ ì›ë³¸ íŒŒì¼ ì•„ì¹´ì´ë¸Œ ì´ë™
            """)
        with col_result2:
            st.success("""
            **ğŸš€ ë‹¤ìŒ ë‹¨ê³„:**
            
            **ğŸ” ê²€ìƒ‰** ë©”ë‰´ë¡œ ì´ë™í•˜ì—¬:
            - í‚¤ì›Œë“œ ê²€ìƒ‰ (ì˜ˆ: ì¹­ì˜, Gnade)
            - AI ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±
            - ì˜µì‹œë””ì–¸ ì—°ë™ ì €ì¥
            """)
        
        # ê²€ìƒ‰ í˜ì´ì§€ë¡œ ì´ë™ ë²„íŠ¼
        col_btn1, col_btn2 = st.columns([1, 1])
        with col_btn1:
            if st.button("ğŸ” ê²€ìƒ‰ ì‹œì‘í•˜ê¸°", type="primary", key="go_to_search", use_container_width=True):
                st.session_state["pipeline_completed"] = False
                st.session_state["page"] = "ğŸ” ê²€ìƒ‰"
                st.rerun()
        with col_btn2:
            if st.button("ğŸ“„ ì¶”ê°€ íŒŒì¼ ë“±ë¡", key="continue_upload", use_container_width=True):
                st.session_state["pipeline_completed"] = False
                st.rerun()
        st.markdown("---")

    st.markdown("""
    PDF íŒŒì¼ì„ ì—…ë¡œë“œí•˜ë©´ ìë™ìœ¼ë¡œ ì²˜ë¦¬ë©ë‹ˆë‹¤:
    1. í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì´ë¯¸ì§€ PDFëŠ” OCR)
    2. ì²­í‚¹ ë° ë©”íƒ€ë°ì´í„° ì¶”ì¶œ
    3. ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ì¸ë±ì‹±
    """)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # [v2.2] ì¸ë±ì‹± ì„¤ì • (ì²­í‚¹ ë‹¨ìœ„ ë° ì˜¤ë²„ë©)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    with st.expander("âš™ï¸ ì¸ë±ì‹± ì„¸ë¶€ ì„¤ì •", expanded=True):
        col1, col2 = st.columns(2)
        with col1:
            chunk_size = st.slider(
                "ì²­í¬ í¬ê¸° (ë¬¸ì ìˆ˜)",
                min_value=500,
                max_value=8000,
                value=2800,
                step=100,
                help="í•œ ë²ˆì— ì¸ë±ì‹±í•  í…ìŠ¤íŠ¸ ë‹¨ìœ„ì…ë‹ˆë‹¤. í´ìˆ˜ë¡ ë¬¸ë§¥ íŒŒì•…ì´ ì¢‹ìœ¼ë‚˜ ì •ë°€ë„ê°€ ë–¨ì–´ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
            )
        with col2:
            overlap = st.slider(
                "ì˜¤ë²„ë© (ë¬¸ì ìˆ˜)",
                min_value=0,
                max_value=2000,
                value=560,
                step=50,
                help="ì²­í¬ ì‚¬ì´ì˜ ê²¹ì¹˜ëŠ” êµ¬ê°„ì…ë‹ˆë‹¤. ë¬¸ë§¥ ì—°ê²°ì„ ë¶€ë“œëŸ½ê²Œ í•©ë‹ˆë‹¤."
            )
        st.caption(f"ğŸ’¡ ëŒ€ëµ {chunk_size//4} ~ {chunk_size//3} í† í° ë‹¨ìœ„ë¡œ ë‚˜ëˆ„ì–´ì§‘ë‹ˆë‹¤.")
        st.info("""
        ğŸ“Œ **ìë£Œë³„ ê¶Œì¥ ì„¤ì •:**
        - **ğŸ“š ì‹ í•™ ì‚¬ì „**: ì²­í¬ 1,000~1,500 / ì˜¤ë²„ë© 200 (í‘œì œì–´ ì¤‘ì‹¬ì˜ ì •ë°€í•œ ê²€ìƒ‰)
        - **ğŸ“– ì¼ë°˜ ë‹¨í–‰ë³¸**: ì²­í¬ 2,500~3,500 / ì˜¤ë²„ë© 500 (í’ë¶€í•œ ë¬¸ë§¥ ìœ ì§€)
        """)

    st.markdown("---")

    st.caption("ğŸ“¦ **ì§€ì› í˜•ì‹:** PDF, TXT, EPUB | **ìµœëŒ€ 1GB** ì—…ë¡œë“œ ê°€ëŠ¥")
    uploaded_files = st.file_uploader(
        "íŒŒì¼ ì„ íƒ",
        type=["pdf", "txt", "epub"],
        accept_multiple_files=True,
        label_visibility="collapsed"
    )

    if uploaded_files:
        st.markdown(f"### ì—…ë¡œë“œëœ íŒŒì¼ ({len(uploaded_files)}ê°œ)")
        
        # [v2.7.23] íŒŒì¼ ì—…ë¡œë“œ ì‹œ ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
        st.info("""
        ğŸ“‹ **ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´:**
        1. ì•„ë˜ì—ì„œ íŒŒì¼ ëª©ë¡ì„ í™•ì¸í•˜ì„¸ìš”
        2. (ì„ íƒ) í˜ì´ì§€ ë§¤í•‘ ì„¤ì • (PDF í˜ì´ì§€ ë²ˆí˜¸ â‰  ì¸ì‡„ë³¸ í˜ì´ì§€)
        3. **ğŸš€ ì²˜ë¦¬ ì‹œì‘** ë²„íŠ¼ì„ í´ë¦­í•˜ë©´ ìë™ìœ¼ë¡œ:
           - í…ìŠ¤íŠ¸ ì¶”ì¶œ â†’ ì²­í‚¹ â†’ ë²¡í„°í™” â†’ ì¸ë±ì‹±ì´ ì§„í–‰ë©ë‹ˆë‹¤
        """)

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ì¤‘ë³µ ì¸ë±ì‹± ì²´í¬
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        duplicates = []
        for f in uploaded_files:
            source_name = Path(f.name).stem
            dup_info = check_duplicate_source(source_name)
            if dup_info["exists"]:
                duplicates.append((f.name, source_name, dup_info))
                st.warning(f"âš ï¸ **{f.name}**: ì´ë¯¸ ì¸ë±ì‹±ë¨ ({dup_info['count']:,}ê°œ ì²­í¬, {dup_info['indexed_at'][:10] if dup_info['indexed_at'] else 'ë‚ ì§œ ë¶ˆëª…'})")
            else:
                st.write(f"âœ… {f.name} ({f.size / 1024:.1f} KB)")

        # ì¤‘ë³µ íŒŒì¼ì´ ìˆì„ ê²½ìš° ì²˜ë¦¬ ì˜µì…˜
        if duplicates:
            st.markdown("---")
            dup_action = st.radio(
                "ì¤‘ë³µ íŒŒì¼ ì²˜ë¦¬ ë°©ë²•",
                ["ìŠ¤í‚µ (ê¸°ì¡´ ìœ ì§€)", "ë®ì–´ì“°ê¸° (ì¬ì¸ë±ì‹±)"],
                key="duplicate_action",
                horizontal=True
            )
            if "duplicate_action_selected" not in st.session_state:
                st.session_state.duplicate_action_selected = dup_action
            else:
                st.session_state.duplicate_action_selected = dup_action

        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # í˜ì´ì§€ ë§¤í•‘ ì„¤ì • (í™•ì¥ íŒ¨ë„)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        with st.expander("ğŸ“– í˜ì´ì§€ ë§¤í•‘ ì„¤ì • (ì„ íƒ)", expanded=False):
            st.caption("PDF í˜ì´ì§€ ë²ˆí˜¸ì™€ ì‹¤ì œ ì¸ì‡„ë³¸ í˜ì´ì§€ ë²ˆí˜¸ê°€ ë‹¤ë¥¸ ê²½ìš° ì„¤ì •í•˜ì„¸ìš”.")

            # ì„¸ì…˜ ìƒíƒœë¡œ ë§¤í•‘ ë°ì´í„° ê´€ë¦¬
            if 'page_mappings' not in st.session_state:
                st.session_state.page_mappings = {}
            if 'sample_counts' not in st.session_state:
                st.session_state.sample_counts = {}

            for uploaded_file in uploaded_files:
                filename = uploaded_file.name
                st.markdown(f"**{filename}**")

                col1, col2 = st.columns(2)

                with col1:
                    use_mapping = st.checkbox(
                        "í˜ì´ì§€ ë§¤í•‘ ì‚¬ìš©",
                        key=f"use_mapping_{filename}",
                        value=filename in st.session_state.page_mappings
                    )

                if use_mapping:
                    # ìƒ˜í”Œ ê°œìˆ˜ ê´€ë¦¬
                    if filename not in st.session_state.sample_counts:
                        st.session_state.sample_counts[filename] = 5  # ê¸°ë³¸ 5ê°œ

                    sample_count = st.session_state.sample_counts[filename]

                    st.caption(f"PDFë¥¼ ì—´ê³  {sample_count}ê°œ ì§€ì ì˜ í˜ì´ì§€ ë²ˆí˜¸ë¥¼ í™•ì¸í•˜ì„¸ìš”:")

                    # ìƒ˜í”Œ ì¶”ê°€/ì œê±° ë²„íŠ¼
                    btn_col1, btn_col2, btn_col3 = st.columns([1, 1, 3])
                    with btn_col1:
                        if st.button("â• ì¶”ê°€", key=f"add_sample_{filename}"):
                            if st.session_state.sample_counts[filename] < 10:
                                st.session_state.sample_counts[filename] += 1
                                st.rerun()
                    with btn_col2:
                        if st.button("â– ì œê±°", key=f"remove_sample_{filename}"):
                            if st.session_state.sample_counts[filename] > 2:
                                st.session_state.sample_counts[filename] -= 1
                                st.rerun()
                    with btn_col3:
                        st.caption(f"(ìµœì†Œ 2ê°œ, ìµœëŒ€ 10ê°œ)")

                    # ê¸°ë³¸ ìƒ˜í”Œ ê°’ ì •ì˜
                    default_samples_all = [
                        (15, 1, "ë³¸ë¬¸ì‹œì‘"),
                        (50, 36, "ì¤‘ê°„1"),
                        (100, 86, "ì¤‘ê°„2"),
                        (150, 136, "ì¤‘ê°„3"),
                        (200, 186, "í›„ë°˜1"),
                        (250, 236, "í›„ë°˜2"),
                        (300, 286, "ë1"),
                        (350, 336, "ë2"),
                        (400, 386, "ë3"),
                        (450, 436, "ë4"),
                    ]

                    # ë™ì  ìƒ˜í”Œ ì…ë ¥
                    samples = []
                    sample_count = st.session_state.sample_counts[filename]

                    # í•œ í–‰ì— ìµœëŒ€ 5ê°œì”© í‘œì‹œ
                    for row_start in range(0, sample_count, 5):
                        row_end = min(row_start + 5, sample_count)
                        cols = st.columns(row_end - row_start)

                        for col_idx, idx in enumerate(range(row_start, row_end)):
                            default_pdf, default_print, label = default_samples_all[idx] if idx < len(default_samples_all) else (100 + idx * 50, 100 + idx * 50 - 14, f"ìƒ˜í”Œ{idx+1}")

                            with cols[col_idx]:
                                st.caption(label)
                                pdf_p = st.number_input(
                                    "PDF",
                                    min_value=1,
                                    value=default_pdf,
                                    key=f"pdf_{filename}_{idx}"
                                )
                                print_p = st.number_input(
                                    "ì¢…ì´",
                                    min_value=0,
                                    value=default_print,
                                    key=f"print_{filename}_{idx}",
                                    help="0 = í˜ì´ì§€ ë²ˆí˜¸ ì—†ìŒ"
                                )
                                samples.append({
                                    "pdf": pdf_p,
                                    "print": print_p if print_p > 0 else None
                                })

                    # ì„¸ì…˜ì— ì €ì¥
                    st.session_state.page_mappings[filename] = samples
                else:
                    if filename in st.session_state.page_mappings:
                        del st.session_state.page_mappings[filename]
                    if filename in st.session_state.sample_counts:
                        del st.session_state.sample_counts[filename]

                st.markdown("---")


        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # ì²˜ë¦¬ ì‹œì‘ ë²„íŠ¼
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if st.button("ğŸš€ ì²˜ë¦¬ ì‹œì‘", type="primary"):
            try:
                # inboxì— ì €ì¥
                INBOX_DIR.mkdir(parents=True, exist_ok=True)

                progress = st.progress(0)
                status = st.empty()

                for i, uploaded_file in enumerate(uploaded_files):
                    filename = uploaded_file.name
                    status.text(f"ì €ì¥ ì¤‘: {filename}")

                    # PDF ì €ì¥
                    file_path = INBOX_DIR / filename
                    with open(file_path, "wb") as f:
                        f.write(uploaded_file.getbuffer())

                    # ë§¤í•‘ íŒŒì¼ ì €ì¥ (ì„¤ì •ëœ ê²½ìš°)
                    if filename in st.session_state.page_mappings:
                        mapping_data = {
                            "type": "samples",
                            "samples": st.session_state.page_mappings[filename]
                        }
                        mapping_path = file_path.with_suffix('.mapping.json')
                        with open(mapping_path, "w", encoding="utf-8") as f:
                            json.dump(mapping_data, f, ensure_ascii=False, indent=2)
                        status.text(f"ë§¤í•‘ ì €ì¥: {mapping_path.name}")

                    progress.progress((i + 1) / len(uploaded_files))

                status.text("íŒŒì¼ ì €ì¥ ì™„ë£Œ. ì²˜ë¦¬ ì‹œì‘...")
                
                # [v2.7.23] ì„¸ì…˜ ìƒíƒœë¡œ íŠ¸ë¦¬ê±°í•˜ì—¬ ì „ì²´ ë„ˆë¹„ ì§„í–‰ë¥  í‘œì‹œ
                st.session_state["run_upload_pipeline"] = True
                st.session_state["upload_chunk_size"] = chunk_size
                st.session_state["upload_overlap"] = overlap
                st.rerun()
            
            except Exception as e:
                st.error(f"âŒ ì‹œìŠ¤í…œ ì˜¤ë¥˜: {e}")
    
    # [v2.7.23] ì—…ë¡œë“œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ì „ì²´ ë„ˆë¹„)
    if st.session_state.get("run_upload_pipeline"):
        st.session_state["run_upload_pipeline"] = False
        run_pipeline(
            st.session_state.get("upload_chunk_size", 2800),
            st.session_state.get("upload_overlap", 560)
        )

    # í˜„ì¬ inbox ìƒíƒœ
    st.markdown("---")
    st.markdown("### ğŸ“¥ Inbox í˜„í™©")

    if INBOX_DIR.exists():
        inbox_files = list(INBOX_DIR.glob("*.pdf")) + list(INBOX_DIR.glob("*.txt"))
        inbox_files = [f for f in inbox_files if not f.name.startswith(".")]

        if inbox_files:
            # [v2.7.23] Inbox íŒŒì¼ ì•ˆë‚´
            st.caption(f"ğŸ’¡ ì•„ë˜ íŒŒì¼ì„ ì„ íƒí•˜ê³  **ğŸš€ ì¸ë±ì‹± ì‹œì‘**ì„ í´ë¦­í•˜ë©´ ì²­í‚¹ â†’ ë²¡í„°í™” â†’ ì¸ë±ì‹±ì´ ìë™ ì§„í–‰ë©ë‹ˆë‹¤.")
            
            # v2.6: íŒŒì¼ ì„ íƒ ë¼ë””ì˜¤ ë²„íŠ¼
            file_options = ["ì „ì²´ ì²˜ë¦¬"] + [f.name for f in inbox_files]
            selected_file_name = st.radio(
                "ì²˜ë¦¬í•  íŒŒì¼ ì„ íƒ",
                options=file_options,
                index=0,
                horizontal=True,
                key="inbox_file_selector"
            )

            col_status, col_idx, col_del = st.columns([2, 1, 1])
            with col_status:
                if selected_file_name == "ì „ì²´ ì²˜ë¦¬":
                    st.info(f"ğŸ“‚ ì´ {len(inbox_files)}ê°œì˜ íŒŒì¼ì´ ëŒ€ê¸° ì¤‘ì…ë‹ˆë‹¤.")
                else:
                    st.success(f"ğŸ“„ ì„ íƒë¨: {selected_file_name}")
            
            with col_idx:
                # v2.5: Inbox ìˆ˜ë™ ì¸ë±ì‹± ë²„íŠ¼ (ì„¸ì…˜ ìƒíƒœë¡œ íŠ¸ë¦¬ê±°)
                if st.button("ğŸš€ ì¸ë±ì‹± ì‹œì‘", key="manual_index", use_container_width=True):
                    st.session_state["run_indexing"] = True
                    st.session_state["indexing_target"] = None if selected_file_name == "ì „ì²´ ì²˜ë¦¬" else str(INBOX_DIR / selected_file_name)
            
            with col_del:
                # v2.7.21: íŒŒì¼ ì‚­ì œ ë²„íŠ¼ (ì „ì²´ ì²˜ë¦¬ê°€ ì•„ë‹ ë•Œë§Œ í™œì„±í™”)
                if selected_file_name != "ì „ì²´ ì²˜ë¦¬":
                    if st.button("ğŸ—‘ï¸ ì‚­ì œ", key="delete_inbox_file", use_container_width=True, type="secondary"):
                        try:
                            file_to_delete = INBOX_DIR / selected_file_name
                            file_to_delete.unlink()
                            st.success(f"âœ… ì‚­ì œ ì™„ë£Œ")
                            st.rerun()
                        except Exception as e:
                            st.error(f"âŒ ì‹¤íŒ¨: {e}")
                else:
                    st.button("ğŸ—‘ï¸ ì‚­ì œ", key="delete_disabled", use_container_width=True, disabled=True)
            
            # [v2.7.23] ì¹¼ëŸ¼ ë°–ì—ì„œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ì „ì²´ ë„ˆë¹„ ì§„í–‰ë¥  í‘œì‹œ)
            if st.session_state.get("run_indexing"):
                st.session_state["run_indexing"] = False
                run_pipeline(chunk_size, overlap, st.session_state.get("indexing_target"))
        else:
            st.caption("ë¹„ì–´ìˆìŒ")
    else:
        st.caption("í´ë” ì—†ìŒ")

# ============================================================
# í†µê³„ í˜ì´ì§€
# ============================================================
elif page == "ğŸ“Š í†µê³„":
    st.markdown("""
        <div style="padding-bottom: 25px;">
            <h1 style="color: #2D3748; font-weight: 800; letter-spacing: -0.5px; margin-bottom: 0;">ğŸ“Š ì„œì¬ í˜„í™©</h1>
            <p style="color: #718096; font-size: 1.1em; font-weight: 400;">í˜„ì¬ ì¸ë±ì‹±ëœ ì‹ í•™ ìë£Œë“¤ì˜ í†µê³„ì™€ ë¶„í¬ì…ë‹ˆë‹¤.</p>
        </div>
    """, unsafe_allow_html=True)
    
    client, collection = load_db(str(DB_PATH))
    index_data = load_lemma_index(str(LEMMA_INDEX_PATH))

    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric(
            "ğŸ“„ ì¸ë±ì‹±ëœ ì²­í¬",
            f"{collection.count():,}ê°œ" if collection else "0ê°œ"
        )

    with col2:
        lemma_count = len(index_data.get("entries", {})) if index_data else 0
        st.metric("ğŸ“– í‘œì œì–´", f"{lemma_count:,}ê°œ")

    with col3:
        archive_files = list(ARCHIVE_DIR.glob("*.json")) if ARCHIVE_DIR.exists() else []
        archive_files = [f for f in archive_files if not f.name.startswith("lemma_")]
        st.metric("ğŸ“š ë³´ê´€ ë¬¸ì„œ", f"{len(archive_files)}ê¶Œ")

    st.markdown("---")

    # ì†ŒìŠ¤ë³„ ë¶„í¬ (ChromaDBì—ì„œ ì§ì ‘ ì¡°íšŒ)
    by_source = get_sources_from_db()

    if by_source:
        import pandas as pd

        total_chunks = sum(info.get("count", 0) for info in by_source.values())

        st.markdown(f"### ğŸ“š ì¸ë±ì‹± ì†ŒìŠ¤ ({len(by_source)}ê°œ, ì´ {total_chunks:,} ì²­í¬)")

        # ì†ŒìŠ¤ ìœ í˜• ë¶„ë¥˜ (ìë™ ì¶”ë¡ )
        SOURCE_TYPES = {
            "TRE": "ì‹ í•™ë°±ê³¼", "RGG": "ì‹ í•™ë°±ê³¼", "EKL": "ì‹ í•™ë°±ê³¼",
            "TDNT": "ì„±ì„œì‚¬ì „", "NIDNTT": "ì„±ì„œì‚¬ì „", "EDNT": "ì„±ì„œì‚¬ì „",
            "ThWAT": "ì„±ì„œì‚¬ì „", "EWNT": "ì„±ì„œì‚¬ì „",
            "HWPh": "ì² í•™ì‚¬ì „",
            "KD": "êµì˜í•™",
        }

        # ë°ì´í„° ì¤€ë¹„
        source_data = []
        for source, info in by_source.items():
            volumes = info.get("volumes", [])
            source_data.append({
                "ì†ŒìŠ¤": source,
                "ìœ í˜•": SOURCE_TYPES.get(source, "ê¸°íƒ€"),
                "ê¶Œìˆ˜": len(volumes) if volumes else 1,
                "ì²­í¬": info.get("count", 0),
            })

        df = pd.DataFrame(source_data).sort_values("ì²­í¬", ascending=False)

        # í•„í„° UI
        col1, col2 = st.columns([2, 1])
        with col1:
            search_source = st.text_input("ì†ŒìŠ¤ ê²€ìƒ‰", placeholder="ì˜ˆ: TRE, RGG...", key="source_search")
        with col2:
            all_types = ["ì „ì²´"] + sorted(df["ìœ í˜•"].unique().tolist())
            selected_type = st.selectbox("ìœ í˜• í•„í„°", all_types, key="type_filter")

        # í•„í„° ì ìš©
        filtered_df = df.copy()
        if search_source:
            filtered_df = filtered_df[filtered_df["ì†ŒìŠ¤"].str.contains(search_source, case=False)]
        if selected_type != "ì „ì²´":
            filtered_df = filtered_df[filtered_df["ìœ í˜•"] == selected_type]

        # í…Œì´ë¸” í‘œì‹œ (ìƒìœ„ 10ê°œ + ë”ë³´ê¸°)
        show_all = st.checkbox(f"ì „ì²´ í‘œì‹œ ({len(filtered_df)}ê°œ)", key="show_all_sources")
        display_df = filtered_df if show_all else filtered_df.head(10)

        st.dataframe(
            display_df,
            column_config={
                "ì†ŒìŠ¤": st.column_config.TextColumn("ì†ŒìŠ¤", width="medium"),
                "ìœ í˜•": st.column_config.TextColumn("ìœ í˜•", width="small"),
                "ê¶Œìˆ˜": st.column_config.NumberColumn("ê¶Œìˆ˜", format="%d"),
                "ì²­í¬": st.column_config.NumberColumn("ì²­í¬", format="%d"),
            },
            hide_index=True,
            width="stretch"
        )

        # ì°¨íŠ¸ (ìƒìœ„ 10ê°œë§Œ)
        if len(df) > 0:
            with st.expander("ğŸ“Š ì²­í¬ ë¶„í¬ ì°¨íŠ¸", expanded=False):
                chart_df = df.head(10).set_index("ì†ŒìŠ¤")[["ì²­í¬"]]
                st.bar_chart(chart_df)

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ì†ŒìŠ¤ ê´€ë¦¬ ì„¹ì…˜
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        st.markdown("---")
        st.markdown("### ğŸ”§ ì†ŒìŠ¤ ê´€ë¦¬")

        # ì†ŒìŠ¤ ì„ íƒ
        source_list = sorted(by_source.keys())
        selected_source = st.selectbox(
            "ê´€ë¦¬í•  ì†ŒìŠ¤ ì„ íƒ",
            ["ì„ íƒí•˜ì„¸ìš”..."] + source_list,
            key="manage_source_select"
        )

        if selected_source and selected_source != "ì„ íƒí•˜ì„¸ìš”...":
            source_info = by_source.get(selected_source, {})
            chunk_count = source_info.get("count", 0)

            col_info, col_actions = st.columns([2, 1])

            with col_info:
                st.info(f"**{selected_source}**: {chunk_count:,}ê°œ ì²­í¬")
                # ì•„ì¹´ì´ë¸Œ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸
                archive_file = ARCHIVE_DIR / f"{selected_source}.json"
                if archive_file.exists():
                    st.success(f"ğŸ“¦ ì•„ì¹´ì´ë¸Œ íŒŒì¼ ì¡´ì¬: {archive_file.name}")
                else:
                    st.warning("âš ï¸ ì•„ì¹´ì´ë¸Œ íŒŒì¼ ì—†ìŒ (ì¬ì¸ë±ì‹± ë¶ˆê°€)")

            with col_actions:
                st.markdown("**ì‘ì—… ì„ íƒ:**")

                # ì‚­ì œ ë²„íŠ¼
                if st.button("ğŸ—‘ï¸ DBì—ì„œ ì‚­ì œ", key=f"delete_{selected_source}", type="secondary"):
                    st.session_state["confirm_delete"] = selected_source

                # ì¬ì¸ë±ì‹± ë²„íŠ¼ (ì•„ì¹´ì´ë¸Œ íŒŒì¼ ìˆì„ ë•Œë§Œ)
                if archive_file.exists():
                    if st.button("ğŸ”„ ì¬ì¸ë±ì‹±", key=f"reindex_{selected_source}", type="primary"):
                        st.session_state["confirm_reindex"] = selected_source

            # ì‚­ì œ í™•ì¸ ë‹¤ì´ì–¼ë¡œê·¸
            if st.session_state.get("confirm_delete") == selected_source:
                st.warning(f"âš ï¸ **'{selected_source}'**ì˜ {chunk_count:,}ê°œ ì²­í¬ë¥¼ ì‚­ì œí•˜ì‹œê² ìŠµë‹ˆê¹Œ?")
                col_yes, col_no = st.columns(2)
                with col_yes:
                    if st.button("âœ… ì‚­ì œ í™•ì¸", key="confirm_delete_yes", type="primary"):
                        with st.spinner("ì‚­ì œ ì¤‘..."):
                            try:
                                deleted = delete_source_from_db(selected_source)
                                st.success(f"âœ… '{selected_source}' ì‚­ì œ ì™„ë£Œ ({deleted}ê°œ ì²­í¬)")
                                st.session_state["confirm_delete"] = None
                                st.rerun()
                            except Exception as e:
                                st.error(f"ì‚­ì œ ì‹¤íŒ¨: {e}")
                with col_no:
                    if st.button("âŒ ì·¨ì†Œ", key="confirm_delete_no"):
                        st.session_state["confirm_delete"] = None
                        st.rerun()

            # ì¬ì¸ë±ì‹± í™•ì¸ ë‹¤ì´ì–¼ë¡œê·¸
            if st.session_state.get("confirm_reindex") == selected_source:
                st.info(f"ğŸ”„ **'{selected_source}'** ì¬ì¸ë±ì‹±: ê¸°ì¡´ ë°ì´í„° ì‚­ì œ í›„ ì•„ì¹´ì´ë¸Œì—ì„œ ë‹¤ì‹œ ì¸ë±ì‹±í•©ë‹ˆë‹¤.")
                col_yes, col_no = st.columns(2)
                with col_yes:
                    if st.button("âœ… ì¬ì¸ë±ì‹± ì‹œì‘", key="confirm_reindex_yes", type="primary"):
                        with st.spinner("ì¬ì¸ë±ì‹± ì¤‘..."):
                            try:
                                result = reindex_source(selected_source)
                                st.success(f"âœ… ì¬ì¸ë±ì‹± ì™„ë£Œ: {result}")
                                st.session_state["confirm_reindex"] = None
                                st.rerun()
                            except Exception as e:
                                st.error(f"ì¬ì¸ë±ì‹± ì‹¤íŒ¨: {e}")
                with col_no:
                    if st.button("âŒ ì·¨ì†Œ", key="confirm_reindex_no"):
                        st.session_state["confirm_reindex"] = None
                        st.rerun()

    else:
        st.info("ì†ŒìŠ¤ ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")

    # ê²½ë¡œ ì •ë³´
    st.markdown("---")
    st.markdown("### ğŸ“‚ ê²½ë¡œ ì •ë³´")
    st.code(f"""
Inbox:   {INBOX_DIR}
Archive: {ARCHIVE_DIR}
DB:      {DB_PATH}
""")

# ============================================================
# ì„¤ì • í˜ì´ì§€
# ============================================================
elif page == "âš™ï¸ ì„¤ì •":
    st.markdown("""
        <div style="padding-bottom: 25px;">
            <h1 style="color: #2D3748; font-weight: 800; letter-spacing: -0.5px; margin-bottom: 0;">âš™ï¸ ì„œì¬ í™˜ê²½ ì„¤ì •</h1>
            <p style="color: #718096; font-size: 1.1em; font-weight: 400;">AI ëª¨ë¸, API í‚¤, ê·¸ë¦¬ê³  ì˜µì‹œë””ì–¸ ë³¼íŠ¸ ê²½ë¡œë¥¼ ê´€ë¦¬í•©ë‹ˆë‹¤.</p>
        </div>
    """, unsafe_allow_html=True)

    # .env íŒŒì¼ ê²½ë¡œ
    ENV_FILE = KIT_ROOT / ".env"

    # í˜„ì¬ ì„¤ì • ë¡œë“œ (ì „ì—­ ì„¤ì • ê¸°ë°˜)
    def load_env_settings():
        return load_global_settings()

    def save_env_settings(settings_to_save: dict):
        """ì„¤ì •ì„ .env íŒŒì¼ì— ì €ì¥"""
        # ê¸°ì¡´ ë‚´ìš© ì½ê¸°
        existing_lines = []
        existing_keys = set()
        if ENV_FILE.exists():
            with open(ENV_FILE, "r", encoding="utf-8") as f:
                for line in f:
                    stripped = line.strip()
                    if stripped and not stripped.startswith("#") and "=" in stripped:
                        key = stripped.split("=", 1)[0].strip()
                        if key in settings_to_save:
                            existing_keys.add(key)
                            existing_lines.append(f"{key}={settings_to_save[key]}\n")
                        else:
                            existing_lines.append(line)
                    else:
                        existing_lines.append(line)

        # ìƒˆ í‚¤ ì¶”ê°€
        for key, value in settings_to_save.items():
            if key not in existing_keys:
                existing_lines.append(f"{key}={value}\n")

        # ì €ì¥
        with open(ENV_FILE, "w", encoding="utf-8") as f:
            f.writelines(existing_lines)

    # ì„¸ì…˜ ìƒíƒœ í™œìš©í•˜ì—¬ ì…ë ¥ê°’ ìœ ì§€
    if "settings_loaded" not in st.session_state:
        st.session_state.current_settings = load_env_settings()
        st.session_state.settings_loaded = True

    settings = st.session_state.current_settings

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì•± íƒ€ì´í‹€ ì„¤ì •
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### ğŸ“ ì•± íƒ€ì´í‹€ ì„¤ì •")
    st.caption("ê²€ìƒ‰ í˜ì´ì§€ì— í‘œì‹œë˜ëŠ” íƒ€ì´í‹€ì„ ìˆ˜ì •í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    app_title_input = st.text_input(
        "ì•± íƒ€ì´í‹€",
        value=settings.get("APP_TITLE", "Theology AI Lab"),
        placeholder="ì˜ˆ: My Digi-Th-Library",
        key="app_title_input"
    )

    st.markdown("---")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì˜µì‹œë””ì–¸ ì„¤ì • (v2.3: ë‹¤ì¤‘ ë³¼íŠ¸ ì´ë ¥ ê´€ë¦¬)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### ğŸ“ Obsidian ì—°ë™ ì„¤ì •")
    st.caption("ê²€ìƒ‰ ê²°ê³¼ë¥¼ Obsidian ë…¸íŠ¸ë¡œ ì €ì¥í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    VAULT_HISTORY_FILE = SCRIPT_DIR / "vault_history.json"
    
    def load_vault_history():
        if VAULT_HISTORY_FILE.exists():
            try:
                with open(VAULT_HISTORY_FILE, "r", encoding="utf-8") as f:
                    return json.load(f)
            except:
                return []
        return []

    def save_vault_history(vault_path):
        history = load_vault_history()
        if vault_path in history:
            history.remove(vault_path)
        history.insert(0, vault_path)
        history = history[:5]  # ìµœê·¼ 5ê°œë§Œ ìœ ì§€
        with open(VAULT_HISTORY_FILE, "w", encoding="utf-8") as f:
            json.dump(history, f, ensure_ascii=False, indent=2)

    vault_history = load_vault_history()
    
    # 1. ìµœê·¼ ì‚¬ìš©ëœ ë³¼íŠ¸ ì„ íƒ
    selected_vault_from_history = ""
    if vault_history:
        selected_vault_from_history = st.selectbox(
            "ìµœê·¼ ì‚¬ìš©ëœ Vault",
            options=["-- ì§ì ‘ ì…ë ¥ --"] + vault_history,
            index=0
        )

    # 2. ë³¼íŠ¸ ê²½ë¡œ ì…ë ¥
    if selected_vault_from_history != "-- ì§ì ‘ ì…ë ¥ --":
        default_vault = selected_vault_from_history
    else:
        default_vault = settings.get("OBSIDIAN_VAULT", "")
    
    obsidian_vault_input = st.text_input(
        "Obsidian Vault ê²½ë¡œ",
        value=default_vault,
        placeholder="ì˜ˆ: /Users/username/Documents/MyVault",
        key="obsidian_vault_input",
        help="Obsidian Vaultì˜ ì „ì²´ ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”"
    )

    # ê²½ë¡œê°€ ë³€ê²½/ì…ë ¥ë˜ë©´ ì´ë ¥ì— ì¶”ê°€
    if obsidian_vault_input and obsidian_vault_input != settings.get("OBSIDIAN_VAULT", ""):
        vault_path = Path(obsidian_vault_input)
        if vault_path.exists():
            save_vault_history(obsidian_vault_input)

    # ê²½ë¡œ ì¡´ì¬ í™•ì¸
    if obsidian_vault_input:
        vault_path = Path(obsidian_vault_input)
        if vault_path.exists():
            st.success(f"âœ… Vault í™•ì¸ë¨: {vault_path.name}")
        else:
            st.warning("âš ï¸ ê²½ë¡œê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")

    st.markdown("---")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 3. API í‚¤ ê´€ë¦¬ (ìƒì‹œ ë…¸ì¶œ, ê°„ì„­ ë°©ì§€)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### ğŸ”‘ API í‚¤ ê´€ë¦¬")
    st.caption("ì‚¬ìš©í•  AI ëª¨ë¸ì˜ API í‚¤ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤. [Anthropic](https://console.anthropic.com/) | [OpenAI](https://platform.openai.com/api-keys) | [Google Gemini](https://aistudio.google.com/app/apikey)")

    # ì €ì¥ëœ í‚¤ ë¡œë“œ (ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´)
    saved_anthropic_key = settings.get("ANTHROPIC_API_KEY", "")
    saved_openai_key = settings.get("OPENAI_API_KEY", "")
    saved_google_key = settings.get("GOOGLE_API_KEY", "")

    col_api1, col_api2, col_api3 = st.columns(3)
    
    with col_api1:
        anthropic_key = st.text_input(
            "Anthropic API Key",
            value=saved_anthropic_key,
            type="password",
            placeholder="sk-ant-api03-...",
            key="anthropic_key_input",
            help="Claude ëª¨ë¸ ì‚¬ìš© ì‹œ í•„ìš”"
        )
    
    with col_api2:
        openai_key = st.text_input(
            "OpenAI API Key",
            value=saved_openai_key,
            type="password",
            placeholder="sk-proj-...",
            key="openai_key_input",
            help="GPT ëª¨ë¸ ì‚¬ìš© ì‹œ í•„ìš”"
        )

    with col_api3:
        google_key = st.text_input(
            "Google API Key",
            value=saved_google_key,
            type="password",
            placeholder="AIza...",
            key="google_key_input",
            help="Gemini ëª¨ë¸ ì‚¬ìš© ì‹œ í•„ìš”"
        )

    st.markdown("---")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # RAG ëª¨ë¸ ì„¤ì • (ì„ íƒëœ í”„ë¡œë°”ì´ë”ì˜ ëª¨ë¸ë§Œ í‘œì‹œ)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # 4. AI ì¶”ë¡  ì—”ì§„ ì„¤ì • (RAG ëª¨ë¸ ì„ íƒ)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("### ğŸ¤– AI ì¶”ë¡  ì—”ì§„ ì„¤ì •")
    st.caption("ì§ˆë¬¸ì— ë‹µë³€í•  ë©”ì¸ AI ëª¨ë¸ì„ ì„ íƒí•©ë‹ˆë‹¤. ìœ„ì—ì„œ ì…ë ¥í•œ API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

    # í”„ë¡œë°”ì´ë”ë³„ ëª¨ë¸ ì •ì˜
    MODELS_BY_PROVIDER = {
        "anthropic": {
            "Claude Opus 4.5 (ìµœì‹ )": "claude-opus-4-5-20251101",
            "Claude Sonnet 4": "claude-sonnet-4-20250514",
            "Claude Haiku 4.5 (ë¹ ë¦„)": "claude-haiku-4-5",
            "Claude 3.5 Sonnet": "claude-3-5-sonnet-20241022",
        },
        "openai": {
            "GPT-5.2 (ìµœì‹ )": "gpt-5.2-2025-12-11",
            "GPT-5.1": "gpt-5.1-2025-11-13",
            "GPT-4.1": "gpt-4.1-2025-04-14",
            "GPT-4.1 Mini (ì €ë ´)": "gpt-4.1-mini-2025-04-14",
            "GPT-4o": "gpt-4o",
        },
        "google": {
            "Gemini 3 Pro (ìµœì‹ )": "gemini-3-pro-preview",
            "Gemini 3 Flash": "gemini-3-flash-preview",
            "Gemini 2.5 Pro": "gemini-2.5-pro",
            "Gemini 2.5 Flash (ì¶”ì²œ)": "gemini-2.5-flash",
            "Gemini 2.0 Flash": "gemini-2.0-flash",
        },
    }

    # í”„ë¡œë°”ì´ë” ì„ íƒ (ë¼ë””ì˜¤ ë²„íŠ¼)
    provider = st.radio(
        "ì‚¬ìš©í•  AI í”„ë¡œë°”ì´ë”",
        ["Anthropic (Claude)", "OpenAI (GPT)", "Google (Gemini)"],
        horizontal=True,
        key="api_provider_select"
    )

    # í”„ë¡œë°”ì´ë” ë§¤í•‘
    provider_map = {
        "Anthropic (Claude)": "anthropic",
        "OpenAI (GPT)": "openai",
        "Google (Gemini)": "google",
    }
    selected_provider = provider_map[provider]

    # ì„ íƒëœ í”„ë¡œë°”ì´ë”ì˜ ëª¨ë¸ë§Œ í‘œì‹œ
    model_options = MODELS_BY_PROVIDER[selected_provider]

    current_model = settings.get("RAG_MODEL", "gemini-2.5-pro")
    # í˜„ì¬ ëª¨ë¸ì´ ì„ íƒëœ í”„ë¡œë°”ì´ë”ì— ìˆëŠ”ì§€ í™•ì¸
    current_model_display = next(
        (k for k, v in model_options.items() if v == current_model),
        list(model_options.keys())[0]  # ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ ëª¨ë¸
    )

    # í˜„ì¬ ëª¨ë¸ì´ ë¦¬ìŠ¤íŠ¸ì— ì—†ìœ¼ë©´ ì¸ë±ìŠ¤ 0 ì‚¬ìš©
    try:
        model_index = list(model_options.keys()).index(current_model_display)
    except ValueError:
        model_index = 0

    selected_model_display = st.selectbox(
        f"{provider} ëª¨ë¸",
        list(model_options.keys()),
        index=model_index,
        key="rag_model_select"
    )
    selected_model = model_options[selected_model_display]

    max_tokens = st.slider(
        "ìµœëŒ€ ì‘ë‹µ í† í°",
        min_value=1024,
        max_value=8192,
        value=int(settings.get("RAG_MAX_TOKENS", 4096)),
        step=256,
        key="rag_max_tokens"
    )

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì €ì¥ ë²„íŠ¼
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("---")

    if st.button("ğŸ’¾ ì„¤ì • ì €ì¥ (Save All)", type="primary"):
        new_settings_data = {
            "ANTHROPIC_API_KEY": anthropic_key,
            "OPENAI_API_KEY": openai_key,
            "GOOGLE_API_KEY": google_key,
            "RAG_MODEL": selected_model,
            "RAG_MAX_TOKENS": str(max_tokens),
            "APP_TITLE": app_title_input,
            "OBSIDIAN_VAULT": obsidian_vault_input,
        }
        try:
            # .env ì €ì¥
            save_env_settings(new_settings_data)
            
            # ì˜µì‹œë””ì–¸ ë³¼íŠ¸ ì´ë ¥ ì €ì¥
            if obsidian_vault_input:
                save_vault_history(obsidian_vault_input)
            
            # ì„¸ì…˜ ìƒíƒœ ì—…ë°ì´íŠ¸
            st.session_state.current_settings = new_settings_data
            
            st.success("âœ… ëª¨ë“  ì„¤ì •ì´ ì•ˆì „í•˜ê²Œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
            st.rerun()  # ì¦‰ì‹œ ë°˜ì˜ì„ ìœ„í•´ ì¬ì‹¤í–‰
            
        except Exception as e:
            st.error(f"âŒ ì €ì¥ ì‹¤íŒ¨: {e}")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # RAG ì‚¬ìš© ê°€ì´ë“œ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("---")
    st.markdown("### ğŸ“– RAG ì‚¬ìš© ê°€ì´ë“œ")

    with st.expander("Claude Desktopì—ì„œ ì‚¬ìš©í•˜ê¸°", expanded=False):
        st.markdown("""
**1. MCP ì„œë²„ ì„¤ì • (claude_desktop_config.json)**

```json
{
  "mcpServers": {
    "theology-lab": {
      "command": "python",
      "args": ["/path/to/03_System/server.py"],
      "env": {
        "ANTHROPIC_API_KEY": "your-api-key"
      }
    }
  }
}
```

**2. ì‚¬ìš© ì˜ˆì‹œ**
- "ì€ì´ì— ëŒ€í•´ ê²€ìƒ‰í•´ì¤˜"
- "TREì—ì„œ Gnade í•­ëª© ì°¾ì•„ì¤˜"
- "ì¹­ì˜ë¡ ê³¼ ê´€ë ¨ëœ ë‚´ìš© ìš”ì•½í•´ì¤˜"
        """)

    with st.expander("API ì§ì ‘ í˜¸ì¶œí•˜ê¸°", expanded=False):
        st.markdown("""
**Python ì˜ˆì‹œ:**

```python
import anthropic

client = anthropic.Anthropic()

# 1. ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ ê´€ë ¨ ë¬¸ì„œ ì°¾ê¸°
results = collection.query(
    query_embeddings=[embedding],
    n_results=5
)

# 2. RAG í”„ë¡¬í”„íŠ¸ ìƒì„±
context = "\\n".join(results["documents"][0])
prompt = f\"\"\"ë‹¤ìŒ ë¬¸ì„œë¥¼ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µí•˜ì„¸ìš”:

{context}

ì§ˆë¬¸: {user_question}
\"\"\"

# 3. Claude í˜¸ì¶œ
response = client.messages.create(
    model="claude-3-5-sonnet-20241022",
    max_tokens=4096,
    messages=[{"role": "user", "content": prompt}]
)
```
        """)

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # GUI ì‚¬ìš© ê°€ì´ë“œ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    st.markdown("---")
    st.markdown("### ğŸ“– GUI ì‚¬ìš© ê°€ì´ë“œ")

    GUI_GUIDE_PATH = KIT_ROOT / "docs" / "GUI_GUIDE.md"

    with st.expander("ì „ì²´ ê°€ì´ë“œ ë³´ê¸°", expanded=False):
        if GUI_GUIDE_PATH.exists():
            guide_content = GUI_GUIDE_PATH.read_text(encoding="utf-8")
            st.markdown(guide_content)
        else:
            st.warning("âš ï¸ ê°€ì´ë“œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.caption(f"ì˜ˆìƒ ê²½ë¡œ: {GUI_GUIDE_PATH}")

    # í˜„ì¬ ìƒíƒœ í‘œì‹œ
    st.markdown("---")
    st.markdown("### ğŸ“Š í˜„ì¬ ìƒíƒœ")

    col1, col2, col3 = st.columns(3)
    with col1:
        if settings.get("ANTHROPIC_API_KEY"):
            st.success("âœ… Anthropic")
        else:
            st.warning("âš ï¸ Anthropic ë¯¸ì„¤ì •")

    with col2:
        if settings.get("OPENAI_API_KEY"):
            st.success("âœ… OpenAI")
        else:
            st.info("â„¹ï¸ OpenAI ë¯¸ì„¤ì •")

    with col3:
        if settings.get("GOOGLE_API_KEY"):
            st.success("âœ… Google")
        else:
            st.info("â„¹ï¸ Google ë¯¸ì„¤ì •")
