#!/usr/bin/env python3
"""
PDF í˜ì´ì§€ ë²ˆí˜¸ ìë™ ê°ì§€ (OCR ê¸°ë°˜)

ì¢…ì´ì±…ì˜ ì‹¤ì œ í˜ì´ì§€ ë²ˆí˜¸ë¥¼ PDFì—ì„œ ìë™ìœ¼ë¡œ ì¶”ì¶œí•˜ì—¬
pdf_page â†’ print_page ë§¤í•‘ í…Œì´ë¸” ìƒì„±

ì§€ì›í•˜ëŠ” í˜ì´ì§€ ë²ˆí˜¸ í˜•ì‹:
- ì•„ë¼ë¹„ì•„ ìˆ«ì: 1, 2, 3, ...
- ë¡œë§ˆ ìˆ«ì: i, ii, iii, iv, v, vi, vii, viii, ix, x, xi, xii, ...
- ë¹ˆ í˜ì´ì§€ (ë²ˆí˜¸ ì—†ìŒ)

ì‚¬ìš©ë²•:
    from page_number_detector import PageNumberDetector

    detector = PageNumberDetector()
    mapping = detector.detect_page_numbers("book.pdf")
    # mapping = {1: None, 2: "i", 3: "ii", ..., 15: 1, 16: 2, ...}
"""

import re
from pathlib import Path
from typing import Dict, Optional, Tuple, List, Union
from dataclasses import dataclass
from enum import Enum

try:
    from pypdf import PdfReader
except ImportError:
    PdfReader = None

try:
    import pytesseract
    from pdf2image import convert_from_path
    OCR_AVAILABLE = True
except ImportError:
    OCR_AVAILABLE = False
    pytesseract = None
    convert_from_path = None


class PageNumberType(Enum):
    """í˜ì´ì§€ ë²ˆí˜¸ ìœ í˜•"""
    ARABIC = "arabic"      # 1, 2, 3, ...
    ROMAN = "roman"        # i, ii, iii, ...
    NONE = "none"          # í˜ì´ì§€ ë²ˆí˜¸ ì—†ìŒ


@dataclass
class PageInfo:
    """í˜ì´ì§€ ì •ë³´"""
    pdf_page: int                           # PDF ë¬¼ë¦¬ì  í˜ì´ì§€ (1-based)
    print_page: Optional[Union[int, str]]   # ì¸ì‡„ë³¸ í˜ì´ì§€ ë²ˆí˜¸ (ë˜ëŠ” ë¡œë§ˆìˆ«ì ë¬¸ìì—´)
    page_type: PageNumberType               # í˜ì´ì§€ ë²ˆí˜¸ ìœ í˜•
    confidence: float                       # ê°ì§€ ì‹ ë¢°ë„ (0.0 ~ 1.0)
    raw_text: str = ""                      # OCRë¡œ ì¶”ì¶œí•œ ì›ë³¸ í…ìŠ¤íŠ¸


class PageNumberDetector:
    """PDF í˜ì´ì§€ ë²ˆí˜¸ ìë™ ê°ì§€ê¸°"""

    # ë¡œë§ˆìˆ«ì ë§¤í•‘
    ROMAN_VALUES = {
        'i': 1, 'ii': 2, 'iii': 3, 'iv': 4, 'v': 5,
        'vi': 6, 'vii': 7, 'viii': 8, 'ix': 9, 'x': 10,
        'xi': 11, 'xii': 12, 'xiii': 13, 'xiv': 14, 'xv': 15,
        'xvi': 16, 'xvii': 17, 'xviii': 18, 'xix': 19, 'xx': 20,
        'xxi': 21, 'xxii': 22, 'xxiii': 23, 'xxiv': 24, 'xxv': 25,
        'xxvi': 26, 'xxvii': 27, 'xxviii': 28, 'xxix': 29, 'xxx': 30,
    }

    # ì•„ë¼ë¹„ì•„ ìˆ«ì íŒ¨í„´ (í˜ì´ì§€ ë²ˆí˜¸ë¡œ ì í•©í•œ ìœ„ì¹˜)
    # ìˆœì„œ ì¤‘ìš”: ë” ì—„ê²©í•œ íŒ¨í„´ ë¨¼ì €
    ARABIC_PATTERNS = [
        r'^\s*(\d{1,3})\s*$',                    # ë‹¨ë… ìˆ«ì (1-3ìë¦¬ë§Œ)
        r'[-â€“â€”]\s*(\d{1,3})\s*[-â€“â€”]',            # ëŒ€ì‹œë¡œ ê°ì‹¼ ìˆ«ì
    ]

    # ì œì™¸í•  ìˆ«ì íŒ¨í„´ (í˜ì´ì§€ ë²ˆí˜¸ê°€ ì•„ë‹Œ ê²ƒë“¤)
    EXCLUDE_PATTERNS = [
        r'19\d{2}',  # ì—°ë„ (1900ë…„ëŒ€)
        r'20\d{2}',  # ì—°ë„ (2000ë…„ëŒ€)
        r'ISBN',     # ISBN ê´€ë ¨
        r'pp?\.\s*\d+',  # ì°¸ì¡° í˜ì´ì§€
    ]

    # ë¡œë§ˆìˆ«ì íŒ¨í„´
    ROMAN_PATTERNS = [
        r'^\s*(x{0,3}(?:ix|iv|v?i{0,3}))\s*$',  # ë‹¨ë… ë¡œë§ˆìˆ«ì
        r'[-â€“â€”]\s*(x{0,3}(?:ix|iv|v?i{0,3}))\s*[-â€“â€”]',  # ëŒ€ì‹œë¡œ ê°ì‹¼ ë¡œë§ˆìˆ«ì
    ]

    def __init__(self, ocr_lang: str = "eng+deu"):
        """
        Args:
            ocr_lang: Tesseract ì–¸ì–´ ì„¤ì • (ê¸°ë³¸: ì˜ì–´+ë…ì¼ì–´)
        """
        self.ocr_lang = ocr_lang
        self._check_dependencies()

    def _check_dependencies(self):
        """ì˜ì¡´ì„± í™•ì¸"""
        if not PdfReader:
            raise ImportError("pypdf íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install pypdf")
        if not OCR_AVAILABLE:
            print("âš ï¸ OCR ì˜ì¡´ì„± ì—†ìŒ (pytesseract, pdf2image). í…ìŠ¤íŠ¸ ì¶”ì¶œë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")

    def detect_page_numbers(
        self,
        pdf_path: str,
        sample_pages: int = 20,
        use_ocr: bool = True,
    ) -> Dict[int, PageInfo]:
        """
        PDFì—ì„œ í˜ì´ì§€ ë²ˆí˜¸ ìë™ ê°ì§€

        Args:
            pdf_path: PDF íŒŒì¼ ê²½ë¡œ
            sample_pages: ìƒ˜í”Œë§í•  í˜ì´ì§€ ìˆ˜ (ì²˜ìŒ Ní˜ì´ì§€)
            use_ocr: OCR ì‚¬ìš© ì—¬ë¶€ (í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ)

        Returns:
            {pdf_page: PageInfo} ë§¤í•‘
        """
        path = Path(pdf_path)
        if not path.exists():
            raise FileNotFoundError(f"íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")

        reader = PdfReader(pdf_path)
        total_pages = len(reader.pages)

        print(f"ğŸ“– {path.name} ({total_pages}í˜ì´ì§€)")
        print(f"   ìƒ˜í”Œë§: ì²˜ìŒ {min(sample_pages, total_pages)}í˜ì´ì§€")

        results: Dict[int, PageInfo] = {}

        # 1ë‹¨ê³„: í…ìŠ¤íŠ¸ ì¶”ì¶œë¡œ í˜ì´ì§€ ë²ˆí˜¸ ê°ì§€
        for pdf_page in range(1, min(sample_pages, total_pages) + 1):
            page = reader.pages[pdf_page - 1]
            text = page.extract_text() or ""

            page_info = self._detect_from_text(pdf_page, text)

            # í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ OCR ì‹œë„
            if page_info.page_type == PageNumberType.NONE and use_ocr and OCR_AVAILABLE:
                page_info = self._detect_from_ocr(pdf_path, pdf_page)

            results[pdf_page] = page_info

        # 2ë‹¨ê³„: íŒ¨í„´ ë¶„ì„ ë° ë³´ì •
        results = self._analyze_and_correct(results)

        # 3ë‹¨ê³„: ì „ì²´ í˜ì´ì§€ë¡œ í™•ì¥ (íŒ¨í„´ ê¸°ë°˜)
        results = self._extend_to_all_pages(results, total_pages)

        # í†µê³„ ì¶œë ¥
        self._print_statistics(results)

        return results

    def _detect_from_text(self, pdf_page: int, text: str) -> PageInfo:
        """í…ìŠ¤íŠ¸ì—ì„œ í˜ì´ì§€ ë²ˆí˜¸ ê°ì§€"""
        # í˜ì´ì§€ í•˜ë‹¨/ìƒë‹¨ ì˜ì—­ ì¶”ì¶œ (í˜ì´ì§€ ë²ˆí˜¸ê°€ ì£¼ë¡œ ìœ„ì¹˜í•˜ëŠ” ê³³)
        lines = text.strip().split('\n')

        # ìƒë‹¨ 3ì¤„ + í•˜ë‹¨ 3ì¤„ ê²€ì‚¬
        check_lines = lines[:3] + lines[-3:] if len(lines) > 6 else lines

        for line in check_lines:
            line = line.strip()
            if not line:
                continue

            # ì œì™¸ íŒ¨í„´ ì²´í¬
            should_exclude = any(re.search(ep, line) for ep in self.EXCLUDE_PATTERNS)
            if should_exclude:
                continue

            # ì•„ë¼ë¹„ì•„ ìˆ«ì ê²€ì‚¬
            for pattern in self.ARABIC_PATTERNS:
                match = re.search(pattern, line)
                if match:
                    num = int(match.group(1))
                    # í˜ì´ì§€ ë²ˆí˜¸ë¡œ ì í•©í•œ ë²”ìœ„ (1-999)
                    if 1 <= num <= 999:
                        return PageInfo(
                            pdf_page=pdf_page,
                            print_page=num,
                            page_type=PageNumberType.ARABIC,
                            confidence=0.8,
                            raw_text=line
                        )

            # ë¡œë§ˆìˆ«ì ê²€ì‚¬
            for pattern in self.ROMAN_PATTERNS:
                match = re.search(pattern, line.lower())
                if match:
                    roman = match.group(1).lower()
                    if roman in self.ROMAN_VALUES:
                        return PageInfo(
                            pdf_page=pdf_page,
                            print_page=roman,
                            page_type=PageNumberType.ROMAN,
                            confidence=0.7,
                            raw_text=line
                        )

        return PageInfo(
            pdf_page=pdf_page,
            print_page=None,
            page_type=PageNumberType.NONE,
            confidence=0.0
        )

    def _detect_from_ocr(self, pdf_path: str, pdf_page: int) -> PageInfo:
        """OCRë¡œ í˜ì´ì§€ ë²ˆí˜¸ ê°ì§€ (í•˜ë‹¨/ìƒë‹¨ ì˜ì—­ë§Œ)"""
        if not OCR_AVAILABLE:
            return PageInfo(
                pdf_page=pdf_page,
                print_page=None,
                page_type=PageNumberType.NONE,
                confidence=0.0
            )

        try:
            # PDF í˜ì´ì§€ë¥¼ ì´ë¯¸ì§€ë¡œ ë³€í™˜ (í•´ë‹¹ í˜ì´ì§€ë§Œ)
            images = convert_from_path(
                pdf_path,
                first_page=pdf_page,
                last_page=pdf_page,
                dpi=150  # ì†ë„ë¥¼ ìœ„í•´ ë‚®ì€ DPI
            )

            if not images:
                return PageInfo(
                    pdf_page=pdf_page,
                    print_page=None,
                    page_type=PageNumberType.NONE,
                    confidence=0.0
                )

            img = images[0]
            width, height = img.size

            # ìƒë‹¨ 10% + í•˜ë‹¨ 10% ì˜ì—­ë§Œ OCR
            regions = [
                img.crop((0, 0, width, int(height * 0.1))),           # ìƒë‹¨
                img.crop((0, int(height * 0.9), width, height)),     # í•˜ë‹¨
            ]

            for region in regions:
                text = pytesseract.image_to_string(region, lang=self.ocr_lang)
                result = self._detect_from_text(pdf_page, text)
                if result.page_type != PageNumberType.NONE:
                    result.confidence *= 0.9  # OCRì€ ì‹ ë¢°ë„ ì•½ê°„ ë‚®ì¶¤
                    return result

        except Exception as e:
            print(f"      âš ï¸ OCR ì˜¤ë¥˜ (p.{pdf_page}): {e}")

        return PageInfo(
            pdf_page=pdf_page,
            print_page=None,
            page_type=PageNumberType.NONE,
            confidence=0.0
        )

    def _analyze_and_correct(self, results: Dict[int, PageInfo]) -> Dict[int, PageInfo]:
        """íŒ¨í„´ ë¶„ì„ ë° ì´ìƒì¹˜ ë³´ì •"""
        # ì—°ì†ì„± ê²€ì‚¬: í˜ì´ì§€ ë²ˆí˜¸ê°€ ìˆœì°¨ì ìœ¼ë¡œ ì¦ê°€í•˜ëŠ”ì§€
        sorted_pages = sorted(results.keys())

        # ì•„ë¼ë¹„ì•„ ìˆ«ì í˜ì´ì§€ë“¤ì˜ ì—°ì†ì„± ê²€ì‚¬
        arabic_pages = [
            (p, results[p].print_page)
            for p in sorted_pages
            if results[p].page_type == PageNumberType.ARABIC
        ]

        if len(arabic_pages) >= 3:
            # ì˜¤í”„ì…‹ ê³„ì‚° (pdf_page - print_page)
            offsets = [pdf - print_p for pdf, print_p in arabic_pages if print_p]
            if offsets:
                # ê°€ì¥ ë¹ˆë²ˆí•œ ì˜¤í”„ì…‹ ì°¾ê¸°
                from collections import Counter
                offset_counts = Counter(offsets)
                most_common_offset = offset_counts.most_common(1)[0][0]

                # ì´ìƒì¹˜ ë³´ì •
                for pdf_page in sorted_pages:
                    info = results[pdf_page]
                    if info.page_type == PageNumberType.ARABIC:
                        expected = pdf_page - most_common_offset
                        if info.print_page != expected and abs(info.print_page - expected) <= 2:
                            # ì˜¤ì°¨ê°€ 2 ì´ë‚´ë©´ ë³´ì •
                            info.print_page = expected
                            info.confidence = 0.6

        return results

    def _extend_to_all_pages(
        self,
        results: Dict[int, PageInfo],
        total_pages: int
    ) -> Dict[int, PageInfo]:
        """ìƒ˜í”Œ ê²°ê³¼ë¥¼ ì „ì²´ í˜ì´ì§€ë¡œ í™•ì¥"""
        # ì˜¤í”„ì…‹ ê³„ì‚°
        arabic_pages = [
            (p, info.print_page)
            for p, info in results.items()
            if info.page_type == PageNumberType.ARABIC and info.print_page
        ]

        if not arabic_pages:
            # ì•„ë¼ë¹„ì•„ ìˆ«ì í˜ì´ì§€ê°€ ì—†ìœ¼ë©´ í™•ì¥ ë¶ˆê°€
            return results

        # í‰ê·  ì˜¤í”„ì…‹ ê³„ì‚°
        offsets = [pdf - print_p for pdf, print_p in arabic_pages]
        avg_offset = round(sum(offsets) / len(offsets))

        # ë³¸ë¬¸ ì‹œì‘ í˜ì´ì§€ ì°¾ê¸° (ì•„ë¼ë¹„ì•„ ìˆ«ìê°€ ì‹œì‘ë˜ëŠ” PDF í˜ì´ì§€)
        first_arabic_pdf = min(p for p, _ in arabic_pages)

        # ì „ì²´ í˜ì´ì§€ í™•ì¥
        for pdf_page in range(1, total_pages + 1):
            if pdf_page not in results:
                if pdf_page >= first_arabic_pdf:
                    # ë³¸ë¬¸ ì˜ì—­: ì•„ë¼ë¹„ì•„ ìˆ«ì
                    results[pdf_page] = PageInfo(
                        pdf_page=pdf_page,
                        print_page=pdf_page - avg_offset,
                        page_type=PageNumberType.ARABIC,
                        confidence=0.5  # ì¶”ì •ê°’
                    )
                else:
                    # ì•ë¶€ë¶„: ë¡œë§ˆìˆ«ì ë˜ëŠ” ì—†ìŒ
                    results[pdf_page] = PageInfo(
                        pdf_page=pdf_page,
                        print_page=None,
                        page_type=PageNumberType.NONE,
                        confidence=0.3
                    )

        return results

    def _print_statistics(self, results: Dict[int, PageInfo]):
        """í†µê³„ ì¶œë ¥"""
        total = len(results)
        arabic = sum(1 for r in results.values() if r.page_type == PageNumberType.ARABIC)
        roman = sum(1 for r in results.values() if r.page_type == PageNumberType.ROMAN)
        none_type = sum(1 for r in results.values() if r.page_type == PageNumberType.NONE)

        avg_conf = sum(r.confidence for r in results.values()) / total if total else 0

        print(f"\n   ğŸ“Š ê°ì§€ ê²°ê³¼:")
        print(f"      - ì•„ë¼ë¹„ì•„: {arabic}í˜ì´ì§€")
        print(f"      - ë¡œë§ˆìˆ«ì: {roman}í˜ì´ì§€")
        print(f"      - ë¯¸ê°ì§€: {none_type}í˜ì´ì§€")
        print(f"      - í‰ê·  ì‹ ë¢°ë„: {avg_conf:.1%}")

        # ì˜¤í”„ì…‹ ì •ë³´
        arabic_pages = [
            (p, r.print_page)
            for p, r in results.items()
            if r.page_type == PageNumberType.ARABIC and r.print_page
        ]
        if arabic_pages:
            first_pdf, first_print = min(arabic_pages, key=lambda x: x[0])
            print(f"      - ë³¸ë¬¸ ì‹œì‘: PDF p.{first_pdf} = ì¢…ì´ p.{first_print}")
            print(f"      - ì˜¤í”„ì…‹: {first_pdf - first_print}")

    def get_print_page(
        self,
        results: Dict[int, PageInfo],
        pdf_page: int
    ) -> Optional[int]:
        """PDF í˜ì´ì§€ì— í•´ë‹¹í•˜ëŠ” ì¢…ì´ì±… í˜ì´ì§€ ë°˜í™˜"""
        if pdf_page not in results:
            return None

        info = results[pdf_page]
        if info.page_type == PageNumberType.ARABIC:
            return info.print_page
        elif info.page_type == PageNumberType.ROMAN:
            # ë¡œë§ˆìˆ«ìëŠ” ìŒìˆ˜ë¡œ ë³€í™˜ (ì •ë ¬/ê²€ìƒ‰ ìš©ì´)
            return -self.ROMAN_VALUES.get(info.print_page, 0)
        else:
            return None

    def create_offset_map(self, results: Dict[int, PageInfo]) -> Dict[int, int]:
        """
        pdf_page â†’ print_page ë‹¨ìˆœ ë§¤í•‘ ìƒì„±
        (local_pdf_processorì™€ í˜¸í™˜)
        """
        mapping = {}
        for pdf_page, info in results.items():
            if info.page_type == PageNumberType.ARABIC and info.print_page:
                mapping[pdf_page] = info.print_page
        return mapping


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLI ì‹¤í–‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    import argparse
    import json

    parser = argparse.ArgumentParser(
        description='PDF í˜ì´ì§€ ë²ˆí˜¸ ìë™ ê°ì§€'
    )
    parser.add_argument('pdf', help='PDF íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--sample', type=int, default=30,
                        help='ìƒ˜í”Œë§í•  í˜ì´ì§€ ìˆ˜ (ê¸°ë³¸: 30)')
    parser.add_argument('--no-ocr', action='store_true',
                        help='OCR ì‚¬ìš© ì•ˆ í•¨ (í…ìŠ¤íŠ¸ ì¶”ì¶œë§Œ)')
    parser.add_argument('--output', '-o', help='ê²°ê³¼ JSON ì €ì¥ ê²½ë¡œ')
    parser.add_argument('--lang', default='eng+deu',
                        help='OCR ì–¸ì–´ (ê¸°ë³¸: eng+deu)')

    args = parser.parse_args()

    print("=" * 60)
    print("ğŸ“– PDF í˜ì´ì§€ ë²ˆí˜¸ ìë™ ê°ì§€")
    print("=" * 60)

    detector = PageNumberDetector(ocr_lang=args.lang)
    results = detector.detect_page_numbers(
        args.pdf,
        sample_pages=args.sample,
        use_ocr=not args.no_ocr
    )

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print("ğŸ“‹ í˜ì´ì§€ ë§¤í•‘ (ì²˜ìŒ 20ê°œ)")
    print("=" * 60)

    for pdf_page in sorted(results.keys())[:20]:
        info = results[pdf_page]
        print_p = info.print_page if info.print_page else "â€”"
        conf = f"({info.confidence:.0%})" if info.confidence > 0 else ""
        print(f"   PDF {pdf_page:3d} â†’ ì¢…ì´ {str(print_p):>5s} {conf}")

    # JSON ì €ì¥
    if args.output:
        output_data = {
            str(k): {
                "pdf_page": v.pdf_page,
                "print_page": v.print_page,
                "type": v.page_type.value,
                "confidence": v.confidence
            }
            for k, v in results.items()
        }
        with open(args.output, 'w', encoding='utf-8') as f:
            json.dump(output_data, f, ensure_ascii=False, indent=2)
        print(f"\nğŸ’¾ ì €ì¥ ì™„ë£Œ: {args.output}")


if __name__ == "__main__":
    main()
