#!/usr/bin/env python3
"""
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ  pipeline.py â€” Theology AI Lab í†µí•© ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸                    â”ƒ
â”ƒ                                                                       â”ƒ
â”ƒ  ê¸°ëŠ¥:                                                                â”ƒ
â”ƒ    1. OCR í•„ìš” ì—¬ë¶€ ìë™ ê°ì§€                                          â”ƒ
â”ƒ    2. OCR ì‹¤í–‰ (ì´ë¯¸ì§€ PDFì¸ ê²½ìš°)                                     â”ƒ
â”ƒ    3. ì²­í‚¹ ë° ë©”íƒ€ë°ì´í„° ì¶”ì¶œ                                          â”ƒ
â”ƒ    4. ChromaDB ì¸ë±ì‹±                                                 â”ƒ
â”ƒ    5. Lemma ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸                                           â”ƒ
â”ƒ                                                                       â”ƒ
â”ƒ  Usage:                                                               â”ƒ
â”ƒ    python pipeline.py                     # inbox ì „ì²´ ì²˜ë¦¬            â”ƒ
â”ƒ    python pipeline.py /path/to/file.pdf   # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬             â”ƒ
â”ƒ                                                                       â”ƒ
â”ƒ  Version: 2.0.0                                                       â”ƒ
â”—â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”›
"""

import os
import sys
import subprocess
import shutil
import logging
from pathlib import Path
from datetime import datetime
from typing import Optional, List, Dict, Any

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=os.getenv("LOG_LEVEL", "INFO"),
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S"
)
logger = logging.getLogger(__name__)


class ProcessingPipeline:
    """í†µí•© ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸"""

    def __init__(self):
        # ìŠ¤í¬ë¦½íŠ¸ ê²½ë¡œ (Docker í™˜ê²½ ê³ ë ¤)
        self.script_dir = Path(__file__).parent.absolute()
        self.tools_dir = self.script_dir.parent / "tools"
        
        # [v2.7.23] kit_root ê¸°ë°˜ ê²½ë¡œ (db_builder.pyì™€ ë™ì¼í•œ ë°©ì‹)
        # utils -> 03_System -> Theology_AI_Lab (Root)
        self.kit_root = self.script_dir.parent.parent
        
        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ ê²½ë¡œ ë¡œë“œ (ìƒëŒ€ ê²½ë¡œì¼ ê²½ìš° kit_root ê¸°ì¤€ìœ¼ë¡œ í•´ì„)
        def resolve_path(env_var: str, default_rel: str) -> Path:
            env_val = os.getenv(env_var)
            if env_val:
                if env_val.startswith("."):
                    return self.kit_root / env_val
                return Path(env_val)
            return self.kit_root / default_rel
        
        self.inbox_dir = resolve_path("INBOX_DIR", "01_Library/inbox")
        self.archive_dir = resolve_path("ARCHIVE_DIR", "01_Library/archive")
        self.db_dir = resolve_path("CHROMA_DB_DIR", "02_Brain/vector_db")
        
        logger.info(f"ğŸ“‚ Kit Root: {self.kit_root}")
        logger.info(f"ğŸ“‚ Inbox: {self.inbox_dir}")

        # OCR ì„¤ì •
        self.ocr_enabled = os.getenv("OCR_ENABLED", "true").lower() == "true"
        self.ocr_languages = os.getenv("OCR_LANGUAGES", "deu+eng+grc+heb+kor")

        # [v2.1] ê°€ìƒí™˜ê²½ Python íƒì§€
        self.python_exe = sys.executable
        venv_python = self.script_dir.parent / "venv" / "bin" / "python3"
        if not venv_python.exists():
            venv_python = self.script_dir.parent / "venv" / "Scripts" / "python.exe"
            
        if venv_python.exists():
            self.python_exe = str(venv_python)
            logger.info(f"ğŸ ê°€ìƒí™˜ê²½ Python ì‚¬ìš©: {self.python_exe}")

    def check_needs_ocr(self, file_path: Path) -> bool:
        """
        PDFê°€ OCRì´ í•„ìš”í•œì§€ í™•ì¸

        Args:
            file_path: PDF íŒŒì¼ ê²½ë¡œ

        Returns:
            True: OCR í•„ìš” (ì´ë¯¸ì§€ PDF)
            False: OCR ë¶ˆí•„ìš” (í…ìŠ¤íŠ¸ í¬í•¨)
        """
        if file_path.suffix.lower() != ".pdf":
            return False

        try:
            from pypdf import PdfReader

            reader = PdfReader(str(file_path))
            total_pages = len(reader.pages)
            check_pages = min(3, total_pages)

            total_chars = 0
            for i in range(check_pages):
                text = reader.pages[i].extract_text() or ""
                total_chars += len(text.strip())

            avg_chars_per_page = total_chars / check_pages if check_pages > 0 else 0

            # í˜ì´ì§€ë‹¹ 50ì ë¯¸ë§Œì´ë©´ OCR í•„ìš”
            needs_ocr = avg_chars_per_page < 50

            if needs_ocr:
                logger.info(f"   ğŸ“· ì´ë¯¸ì§€ PDF ê°ì§€: í‰ê·  {avg_chars_per_page:.0f}ì/í˜ì´ì§€")
            else:
                logger.info(f"   ğŸ“ í…ìŠ¤íŠ¸ PDF ê°ì§€: í‰ê·  {avg_chars_per_page:.0f}ì/í˜ì´ì§€")

            return needs_ocr

        except Exception as e:
            logger.warning(f"   âš ï¸  PDF í™•ì¸ ì˜¤ë¥˜: {e}")
            return False

    def run_ocr(self, file_path: Path) -> Optional[Path]:
        """
        OCR ì‹¤í–‰ í›„ í…ìŠ¤íŠ¸ íŒŒì¼ ë°˜í™˜

        Args:
            file_path: PDF íŒŒì¼ ê²½ë¡œ

        Returns:
            OCR ê²°ê³¼ í…ìŠ¤íŠ¸ íŒŒì¼ ê²½ë¡œ (ì‹¤íŒ¨ ì‹œ None)
        """
        try:
            from ocr_pdf_processor import ocr_pdf, check_pdf_has_text
        except ImportError:
            # ocr_pdf_processorê°€ ì—†ìœ¼ë©´ ì§ì ‘ êµ¬í˜„
            logger.warning("   âš ï¸  ocr_pdf_processor ëª¨ë“ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

        output_path = file_path.with_suffix(".txt")

        logger.info(f"   ğŸ” OCR ì²˜ë¦¬ ì¤‘... (ì–¸ì–´: {self.ocr_languages})")

        try:
            text = ocr_pdf(
                str(file_path),
                output_path=str(output_path),
                languages=self.ocr_languages
            )

            if output_path.exists():
                logger.info(f"   âœ… OCR ì™„ë£Œ: {output_path.name}")
                return output_path
            else:
                logger.error(f"   âŒ OCR ê²°ê³¼ íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
                return None

        except Exception as e:
            logger.error(f"   âŒ OCR ì‹¤íŒ¨: {e}")
            return None

    def run_processor(self, file_path: Path, chunk_size: int = 2800, overlap: int = 560) -> bool:
        """
        PDF/TXT ì²˜ë¦¬ (local_pdf_processor.py í˜¸ì¶œ)

        Args:
            file_path: ì²˜ë¦¬í•  íŒŒì¼ ê²½ë¡œ
            chunk_size: ì²­í¬ í¬ê¸°
            overlap: ì˜¤ë²„ë© í¬ê¸°

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        processor_script = self.script_dir / "local_pdf_processor.py"

        if not processor_script.exists():
            logger.error(f"   âŒ í”„ë¡œì„¸ì„œ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {processor_script}")
            return False

        logger.info(f"   ğŸ“„ ì²­í‚¹ ì²˜ë¦¬ ì¤‘ (Size: {chunk_size}, Overlap: {overlap})...")

        try:
            # v2.2: ì‹¤ì‹œê°„ ë¡œê·¸ ì¶œë ¥ì„ ìœ„í•´ Popen ì‚¬ìš© ê°€ëŠ¥í•˜ì§€ë§Œ, 
            # ì—¬ê¸°ì„œëŠ” ì¼ë‹¨ ì¼ê´€ì„±ì„ ìœ„í•´ ë§¤ê°œë³€ìˆ˜ ì „ë‹¬ì— ì§‘ì¤‘
            cmd = [
                self.python_exe,
                str(processor_script),
                str(file_path),
                "-o", str(self.inbox_dir),
                "--chunk-size", str(chunk_size),
                "--overlap", str(overlap)
            ]
            
            # ì‹¤ì‹œê°„ ë¡œê·¸ ì¶œë ¥ì„ ìœ„í•´ ì§ì ‘ ì‹¤í–‰ (Streamlitì—ì„œ ìº¡ì²˜ ê°€ëŠ¥í•˜ë„ë¡)
            process = subprocess.Popen(
                cmd,
                stdout=subprocess.PIPE,
                stderr=subprocess.STDOUT,
                text=True,
                bufsize=1,
                universal_newlines=True
            )

            for line in process.stdout:
                line = line.strip()
                if line:
                    # [PROGRESS] íƒœê·¸ê°€ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì¶œë ¥í•˜ì—¬ app.pyì—ì„œ ì¸ì‹ ê°€ëŠ¥í•˜ê²Œ í•¨
                    print(line, flush=True)
                    if "[PROGRESS]" not in line:
                        logger.debug(f"      {line}")

            process.wait()

            if process.returncode == 0:
                logger.info(f"   âœ… ì²­í‚¹ ì™„ë£Œ")
                return True
            else:
                logger.error(f"   âŒ ì²­í‚¹ ì‹¤íŒ¨ (Exit Code: {process.returncode})")
                return False

        except Exception as e:
            logger.error(f"   âŒ ì²­í‚¹ ì˜¤ë¥˜: {e}")
            return False

    def run_db_builder(self) -> bool:
        """
        ChromaDB ì¸ë±ì‹± ì‹¤í–‰ (db_builder.py í˜¸ì¶œ)

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        db_builder_script = self.script_dir / "db_builder.py"

        if not db_builder_script.exists():
            logger.error(f"   âŒ DB ë¹Œë” ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {db_builder_script}")
            return False

        logger.info(f"   ğŸ—„ï¸  ë²¡í„° DB ì¸ë±ì‹± ì¤‘...")

        try:
            result = subprocess.run(
                [self.python_exe, str(db_builder_script)],
                capture_output=True,
                text=True,
                timeout=600  # 10ë¶„ íƒ€ì„ì•„ì›ƒ
            )

            if result.returncode == 0:
                logger.info(f"   âœ… ì¸ë±ì‹± ì™„ë£Œ")
                return True
            else:
                logger.error(f"   âŒ ì¸ë±ì‹± ì‹¤íŒ¨: {result.stderr}")
                return False

        except subprocess.TimeoutExpired:
            logger.error(f"   âŒ ì¸ë±ì‹± ì‹œê°„ ì´ˆê³¼")
            return False
        except Exception as e:
            logger.error(f"   âŒ ì¸ë±ì‹± ì˜¤ë¥˜: {e}")
            return False

    def run_lemma_indexer(self) -> bool:
        """
        Lemma ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ (build_lemma_index.py í˜¸ì¶œ)

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        indexer_script = self.tools_dir / "build_lemma_index.py"

        if not indexer_script.exists():
            logger.warning(f"   âš ï¸  Lemma ì¸ë±ì„œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {indexer_script}")
            return True  # ì„ íƒì  ë‹¨ê³„

        logger.info(f"   ğŸ“‘ Lemma ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì¤‘...")

        try:
            result = subprocess.run(
                [self.python_exe, str(indexer_script)],
                capture_output=True,
                text=True,
                timeout=120  # 2ë¶„ íƒ€ì„ì•„ì›ƒ
            )

            if result.returncode == 0:
                logger.info(f"   âœ… ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì™„ë£Œ")
                return True
            else:
                logger.warning(f"   âš ï¸  ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ê²½ê³ : {result.stderr}")
                return True  # ê²½ê³ ë§Œ í‘œì‹œ

        except Exception as e:
            logger.warning(f"   âš ï¸  ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì˜¤ë¥˜: {e}")
            return True  # ì„ íƒì  ë‹¨ê³„

    def process_file(self, file_path: Path, chunk_size: int = 2800, overlap: int = 560) -> Dict[str, Any]:
        """
        ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ (ì „ì²´ íŒŒì´í”„ë¼ì¸)

        Args:
            file_path: ì²˜ë¦¬í•  íŒŒì¼ ê²½ë¡œ
            chunk_size: ì²­í¬ í¬ê¸°
            overlap: ì˜¤ë²„ë© í¬ê¸°

        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        result = {
            "file": file_path.name,
            "status": "pending",
            "ocr_applied": False,
            "started_at": datetime.now().isoformat(),
            "errors": []
        }

        logger.info(f"\nğŸ“‚ íŒŒì¼ ì²˜ë¦¬ ì‹œì‘: {file_path.name}")

        # 1. OCR í•„ìš” ì—¬ë¶€ í™•ì¸ ë° ì‹¤í–‰
        if self.ocr_enabled and file_path.suffix.lower() == ".pdf":
            if self.check_needs_ocr(file_path):
                ocr_result = self.run_ocr(file_path)
                if ocr_result:
                    result["ocr_applied"] = True
                    file_path = ocr_result  # OCR ê²°ê³¼ë¡œ ëŒ€ì²´
                else:
                    result["errors"].append("OCR ì‹¤íŒ¨")
                    # OCR ì‹¤íŒ¨í•´ë„ ì›ë³¸ìœ¼ë¡œ ê³„ì† ì§„í–‰

        # 2. ì²­í‚¹ ì²˜ë¦¬
        if not self.run_processor(file_path, chunk_size=chunk_size, overlap=overlap):
            result["errors"].append("ì²­í‚¹ ì‹¤íŒ¨")
            result["status"] = "failed"
            return result

        result["status"] = "success"
        result["completed_at"] = datetime.now().isoformat()

        return result

    def cleanup_processed_file(self, file_path: Path) -> bool:
        """
        ì²˜ë¦¬ ì™„ë£Œëœ íŒŒì¼ ì •ë¦¬
        - JSON (ì²­í‚¹ ê²°ê³¼) â†’ archive/ë¡œ ì´ë™ (ê²€ìƒ‰ ë°ì´í„°)
        - PDF/TXT/ë§¤í•‘ íŒŒì¼ â†’ ì‚­ì œ (ì‚¬ìš©ì ì›ë³¸ì€ ë³„ë„ ë³´ê´€)

        Args:
            file_path: ì›ë³¸ íŒŒì¼ ê²½ë¡œ

        Returns:
            ì„±ê³µ ì—¬ë¶€
        """
        try:
            stem = file_path.stem
            
            # 1. JSON íŒŒì¼ì„ archiveë¡œ ì´ë™ (ê²€ìƒ‰ìš© ë°ì´í„°)
            json_file = file_path.with_suffix(".json")
            if json_file.exists():
                self.archive_dir.mkdir(parents=True, exist_ok=True)
                dest = self.archive_dir / json_file.name
                shutil.move(str(json_file), str(dest))
                logger.info(f"   ğŸ“¦ ì´ë™: {json_file.name} â†’ archive/")
            
            # 2. ì„ì‹œ íŒŒì¼ë“¤ ì‚­ì œ (PDF, ë§¤í•‘, OCR TXT)
            temp_files = [
                file_path,                              # ì›ë³¸ PDF
                file_path.with_suffix(".mapping.json"), # ë§¤í•‘ íŒŒì¼
                file_path.with_suffix(".txt"),          # OCR ê²°ê³¼
            ]
            
            for f in temp_files:
                if f.exists():
                    f.unlink()
                    logger.info(f"   ğŸ—‘ï¸  ì‚­ì œ: {f.name}")

            return True

        except Exception as e:
            logger.warning(f"   âš ï¸  íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {e}")
            return False

    def process_inbox(self, chunk_size: int = 2800, overlap: int = 560) -> Dict[str, Any]:
        """
        inbox í´ë” ì „ì²´ ì²˜ë¦¬

        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½
        """
        summary = {
            "started_at": datetime.now().isoformat(),
            "files_processed": 0,
            "files_failed": 0,
            "ocr_applied": 0,
            "results": []
        }

        logger.info("=" * 60)
        logger.info("ğŸ­ Theology AI Lab - í†µí•© íŒŒì´í”„ë¼ì¸ ì‹œì‘")
        logger.info("=" * 60)
        logger.info(f"ğŸ“‚ Inbox: {self.inbox_dir}")
        logger.info(f"ğŸ“‚ Archive: {self.archive_dir}")
        logger.info(f"ğŸ” OCR í™œì„±í™”: {self.ocr_enabled}")
        logger.info(f"ğŸ“ ì¸ë±ì‹± ì„¤ì •: Chunk={chunk_size}, Overlap={overlap}")

        # ì²˜ë¦¬í•  íŒŒì¼ ëª©ë¡
        files = list(self.inbox_dir.glob("*.pdf")) + list(self.inbox_dir.glob("*.txt")) + list(self.inbox_dir.glob("*.epub"))

        # JSON íŒŒì¼ì€ ì œì™¸ (ì´ë¯¸ ì²˜ë¦¬ë¨)
        files = [f for f in files if not f.name.endswith(".json")]

        if not files:
            logger.info("\nâœ… ì²˜ë¦¬í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
            return summary

        logger.info(f"\nğŸ“„ ë°œê²¬ëœ íŒŒì¼: {len(files)}ê°œ")
        total_files = len(files)

        # ê°œë³„ íŒŒì¼ ì²˜ë¦¬
        processed_files = []  # ì„±ê³µí•œ íŒŒì¼ ëª©ë¡

        for i, file_path in enumerate(files, 1):
            # [v2.7.23] ê°œì„ ëœ ì§„í–‰ë¥  í‘œì‹œ
            progress_pct = int((i - 1) / total_files * 80)  # íŒŒì¼ ì²˜ë¦¬ëŠ” 0-80%
            print(f"[PROGRESS] {progress_pct}% ({i}/{total_files}) ğŸ“„ {file_path.name} ì²˜ë¦¬ ì¤‘...", flush=True)
            
            logger.info(f"\n[{i}/{len(files)}] {'â”€' * 50}")
            result = self.process_file(file_path, chunk_size=chunk_size, overlap=overlap)
            summary["results"].append(result)

            if result["status"] == "success":
                summary["files_processed"] += 1
                processed_files.append(file_path)
                progress_pct = int(i / total_files * 80)
                print(f"[PROGRESS] {progress_pct}% ({i}/{total_files}) âœ… {file_path.name} ì™„ë£Œ", flush=True)
            else:
                summary["files_failed"] += 1
                print(f"[PROGRESS] {progress_pct}% âŒ {file_path.name} ì‹¤íŒ¨", flush=True)

            if result.get("ocr_applied"):
                summary["ocr_applied"] += 1

        # DB ì¸ë±ì‹± (ì „ì²´ ì²˜ë¦¬ í›„ í•œ ë²ˆë§Œ)
        logger.info(f"\n{'â”€' * 60}")
        if summary["files_processed"] > 0:
            print(f"[PROGRESS] 85% ğŸ—„ï¸ ë²¡í„° DB ì¸ë±ì‹± ì‹œì‘...", flush=True)
            self.run_db_builder()
            print(f"[PROGRESS] 95% ğŸ“‘ Lemma ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì¤‘...", flush=True)
            self.run_lemma_indexer()

            # ì„±ê³µí•œ íŒŒì¼ë“¤ inboxì—ì„œ ì •ë¦¬
            logger.info(f"\nğŸ§¹ ì²˜ë¦¬ ì™„ë£Œëœ íŒŒì¼ ì •ë¦¬ ì¤‘...")
            for file_path in processed_files:
                self.cleanup_processed_file(file_path)

        # ì™„ë£Œ ìš”ì•½
        summary["completed_at"] = datetime.now().isoformat()
        print(f"[PROGRESS] 100% (íŒŒì´í”„ë¼ì¸ ì™„ë£Œ)")

        logger.info("\n" + "=" * 60)
        logger.info("ğŸ‰ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ!")
        logger.info("=" * 60)
        logger.info(f"   âœ… ì„±ê³µ: {summary['files_processed']}ê°œ")
        logger.info(f"   âŒ ì‹¤íŒ¨: {summary['files_failed']}ê°œ")
        logger.info(f"   ğŸ“· OCR ì ìš©: {summary['ocr_applied']}ê°œ")
        logger.info("=" * 60)

        return summary


def main():
    """CLI ì—”íŠ¸ë¦¬í¬ì¸íŠ¸"""
    import argparse

    parser = argparse.ArgumentParser(
        description="Theology AI Lab - í†µí•© ì²˜ë¦¬ íŒŒì´í”„ë¼ì¸",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì˜ˆì‹œ:
  # inbox ì „ì²´ ì²˜ë¦¬
  python pipeline.py

  # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
  python pipeline.py /path/to/document.pdf

  # OCR ë¹„í™œì„±í™”
  OCR_ENABLED=false python pipeline.py
        """
    )

    parser.add_argument(
        "input",
        nargs="?",
        help="ì²˜ë¦¬í•  íŒŒì¼ ê²½ë¡œ (ìƒëµ ì‹œ inbox ì „ì²´ ì²˜ë¦¬)"
    )

    parser.add_argument(
        "--chunk-size",
        type=int,
        default=2800,
        help="ì²­í¬ í¬ê¸° (ë¬¸ì ìˆ˜)"
    )

    parser.add_argument(
        "--overlap",
        type=int,
        default=560,
        help="ì²­í¬ ì˜¤ë²„ë© (ë¬¸ì ìˆ˜)"
    )

    parser.add_argument(
        "--no-ocr",
        action="store_true",
        help="OCR ì²˜ë¦¬ ë¹„í™œì„±í™”"
    )

    args = parser.parse_args()

    # OCR ë¹„í™œì„±í™” ì˜µì…˜ ì²˜ë¦¬
    if args.no_ocr:
        os.environ["OCR_ENABLED"] = "false"

    # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    pipeline = ProcessingPipeline()

    if args.input:
        # ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬
        file_path = Path(args.input)
        if not file_path.exists():
            logger.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {args.input}")
            sys.exit(1)

        result = pipeline.process_file(file_path, chunk_size=args.chunk_size, overlap=args.overlap)

        # DB ì¸ë±ì‹±
        if result["status"] == "success":
            print(f"[PROGRESS] 95% (ë²¡í„° DB ë¹Œë“œ ì¤‘...)")
            pipeline.run_db_builder()
            print(f"[PROGRESS] 98% (Lemma ì¸ë±ìŠ¤ ì—…ë°ì´íŠ¸ ì¤‘...)")
            pipeline.run_lemma_indexer()
            
            # v2.7.22: ë‹¨ì¼ íŒŒì¼ ì²˜ë¦¬ ì„±ê³µ í›„ì—ë„ ì •ë¦¬ ìˆ˜í–‰
            print(f"[PROGRESS] 99% (íŒŒì¼ ì •ë¦¬ ì¤‘...)")
            pipeline.cleanup_processed_file(file_path)
            
            print(f"[PROGRESS] 100% (ì™„ë£Œ)")

        sys.exit(0 if result["status"] == "success" else 1)
    else:
        # inbox ì „ì²´ ì²˜ë¦¬
        summary = pipeline.process_inbox(chunk_size=args.chunk_size, overlap=args.overlap)
        sys.exit(0 if summary["files_failed"] == 0 else 1)


if __name__ == "__main__":
    main()
